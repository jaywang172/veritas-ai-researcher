# Veritas：基於多代理架構的自動化學術研究框架

## 摘要

本研究提出 Veritas 系統，一個利用專業化人工智慧代理協同運作的自主式多代理系統，旨在促進全面性學術研究的進行。該系統運用大型語言模型（Large Language Models, LLMs）與圖形化工作流引擎，自動化整個研究流程，涵蓋文獻回顧至手稿撰寫。建構於 CrewAI 多代理框架與 LangGraph 工作流引擎之上，Veritas 實作了協作式架構，由八個專業化代理執行不同研究任務：文獻蒐集、綜合分析、大綱規劃、學術寫作、編輯審閱、引文格式化、計算分析與專案管理。系統展現了自動化研究輔助的可行性，同時維持學術嚴謹性與引用完整性。本實作支援多種研究模式，包括純文獻回顧、數據驅動分析與混合方法論。實驗驗證顯示，Veritas 能顯著減少研究準備時間，同時產出具學術水準且適當註明來源的成果。

**關鍵詞**：多代理系統、大型語言模型、自動化研究、學術寫作、知識綜合、CrewAI、LangGraph

---

## 1. 緒論

### 1.1 研究問題

學術文獻與數據來源的指數級成長，對試圖進行全面性文獻回顧與數據分析的研究人員構成重大挑戰。傳統研究方法論需要大量時間投資於文獻蒐集、綜合、分析與手稿準備。本研究引入一個自動化系統，透過智能代理協調來解決這些挑戰。

### 1.2 系統概述

Veritas（版本 3.1）是一個先進的研究自動化平台，實作了多代理架構以協助學術研究。系統採用八個專業化 AI 代理，每個針對特定研究任務進行最佳化，透過工作流引擎協調，確保適當的任務排序與資訊流動。

### 1.3 研究貢獻

本研究的主要貢獻包括：

1. **多代理架構**：創新的八代理系統，具備專業化角色與針對各任務最佳化的 LLM 配置
2. **混合研究能力**：支援純文獻回顧、計算數據分析與結合方法論
3. **品質保證框架**：具量化評分機制的自動化審閱循環
4. **版本控制系統**：工作流程中研究產出物的完整版本控制
5. **引用完整性**：自動化來源追蹤與 APA 第七版引文格式化

---

## 2. 系統架構

### 2.1 多代理框架

系統實作八個建構於 CrewAI 框架上的專業化代理：

**代理一：文獻蒐集專家**
- **角色**：文獻蒐集與網路基礎研究
- **LLM 配置**：GPT-4o-mini（針對搜尋任務進行成本最佳化）
- **工具**：Tavily 搜尋 API 用於學術資源探索
- **目標**：根據研究查詢識別並檢索相關學術來源

**代理二：研究分析師（綜合者）**
- **角色**：從原始研究數據中提取關鍵論點與證據
- **LLM 配置**：GPT-4.1-mini（平衡效能）
- **輸出格式**：結構化 JSON，包含論述-來源配對
- **目標**：將非結構化研究數據轉換為結構化論點清單

**代理三：大綱規劃師**
- **角色**：邏輯結構設計與章節組織
- **LLM 配置**：O3-mini（進階推理能力）
- **輸出格式**：階層式 JSON 大綱，含章節分配
- **目標**：從提取的論點創建連貫的論證結構

**代理四：學術寫作專家**
- **角色**：學術手稿撰寫
- **LLM 配置**：GPT-5-mini（進階創作能力）
- **引用協定**：內文 URL 引用格式（來源 URL）
- **目標**：生成具學術嚴謹性且適當註明出處的文稿

**代理五：編輯審閱師**
- **角色**：內容精煉與連貫性驗證
- **LLM 配置**：GPT-5（頂級語言精通度）
- **任務**：摘要生成、轉折增強、風格統一
- **目標**：確保手稿品質與邏輯流暢

**代理六：引文格式化師**
- **角色**：以 APA 第七版格式生成參考文獻清單
- **LLM 配置**：GPT-4.1-mini（精確格式化能力）
- **工具**：Tavily 搜尋用於元數據提取
- **目標**：創建格式正確的書目條目

**代理七：計算科學家**
- **角色**：數據分析與視覺化
- **LLM 配置**：GPT-4.1（可靠的工具使用）
- **工具**：FileReadTool、LocalCodeExecutor
- **函式庫**：pandas、numpy、matplotlib、seaborn、scikit-learn
- **目標**：執行統計分析並生成出版級視覺化圖表

**代理八：專案經理**
- **角色**：策略規劃與工作流協調
- **LLM 配置**：O3（頂級策略推理）
- **委派**：啟用任務分配功能
- **目標**：最佳化研究策略並協調代理活動

### 2.2 LLM 配置策略

系統透過差異化模型選擇採用成本效能最佳化策略：

| 代理類型 | 模型 | 層級 | 成本/千個詞元 | 理由 |
|---------|------|------|--------------|------|
| 文獻蒐集專家 | gpt-4o-mini | 基礎 | $0.26 | 高流量搜尋任務 |
| 研究分析師 | gpt-4.1-mini | 標準 | $0.50 | 結構化提取 |
| 大綱規劃師 | o3-mini | 進階 | $1.93 | 需要複雜推理 |
| 學術寫作專家 | gpt-5-mini | 進階 | $0.63 | 創意寫作 |
| 編輯審閱師 | gpt-5 | 頂級 | $2.63 | 語言專業度關鍵 |
| 引文格式化師 | gpt-4.1-mini | 標準 | $0.50 | 精確格式化 |
| 計算科學家 | gpt-4.1 | 頂級 | $2.50 | 可靠的程式碼生成 |
| 專案經理 | o3 | 頂級 | $3.00 | 策略決策 |

### 2.3 工作流引擎架構

系統利用 LangGraph（基於狀態機的工作流引擎）來協調代理互動：

```
graph TB
    A[使用者輸入] --> B[專案經理]
    B --> C{研究類型偵測}
    C -->|文獻型| D[文獻蒐集專家]
    C -->|數據分析| E[計算科學家]
    C -->|混合型| F[平行執行]
    F --> D
    F --> E
    D --> G[研究分析師]
    E --> G
    G --> H[大綱規劃師]
    H --> I[學術寫作專家]
    I --> J[編輯審閱循環]
    J -->|分數 < 7| I
    J -->|分數 >= 7| K[引文格式化師]
    K --> L[最終文件]
```

### 2.4 品質保證系統

系統實作迭代式審閱機制：

1. **初稿生成**：學術寫作專家產出章節內容
2. **品質評分**：編輯審閱師指派 1-10 品質分數
3. **決策邏輯**：
   - 接受（ACCEPT）：分數 >= 7，進行下一階段
   - 修訂（REVISE）：分數 4-6，回傳修訂並提供具體回饋
   - 拒絕（REJECT）：分數 < 4，需根本性重組
4. **修訂限制**：最多 2 次修訂循環以防止無限迴圈
5. **版本追蹤**：所有版本均存檔，含時間戳記與分數

---

## 3. 系統實作

### 3.1 技術堆疊

**核心相依套件**：
- Python 3.10+
- CrewAI >= 0.177.0（多代理協調）
- LangGraph >= 0.2.0（工作流引擎）
- LangChain-OpenAI >= 0.1.0（LLM 整合）
- FastAPI >= 0.104.0（Web API 框架）
- Uvicorn >= 0.24.0（ASGI 伺服器）

**資料科學函式庫**：
- pandas >= 2.3.0（資料操作）
- numpy >= 2.3.0（數值計算）
- scipy >= 1.13.0（科學計算）
- statsmodels >= 0.14.0（統計建模）
- matplotlib >= 3.8.0（視覺化）
- seaborn >= 0.13.0（統計圖形）
- scikit-learn >= 1.4.0（機器學習）

**搜尋與網路整合**：
- tavily-python >= 0.3.0（學術搜尋 API）
- requests >= 2.32.0（HTTP 客戶端）
- beautifulsoup4 >= 4.13.0（網頁擷取）

### 3.2 安裝與部署

**先決條件**：
- Python 3.10 或更高版本
- 最低 8GB RAM（建議 16GB）
- 2GB 可用磁碟空間
- 穩定的網際網路連線以存取 API

**安裝程序**：

```bash
# 複製儲存庫
git clone https://github.com/jaywang172/veritas-ai-researcher.git
cd veritas-ai-researcher

# 建立虛擬環境
python -m venv .venv

# 啟動虛擬環境
# Unix/Linux/macOS:
source .venv/bin/activate
# Windows:
# .venv\Scripts\activate

# 安裝相依套件
pip install -r requirements.txt

# 配置 API 憑證
python setup_api_keys.py
```

**環境配置**：

建立包含必要 API 金鑰的 `.env` 檔案：

```
OPENAI_API_KEY=您的_openai_api_金鑰
TAVILY_API_KEY=您的_tavily_api_金鑰
```

**前端編譯**（選擇性）：

```bash
cd frontend
npm install
npm run build
cd ..
```

**系統啟動**：

```bash
# 啟動整合前端的 Web 伺服器
python api_server.py

# 存取 Web 介面：http://localhost:8000
# API 文件：http://localhost:8000/docs
```

### 3.3 API 端點

系統公開 RESTful API 供程式化存取：

- **POST /api/execute**：執行研究工作流
- **POST /api/upload**：上傳分析用資料檔案
- **GET /api/status**：查詢目前執行狀態
- **GET /api/results/{session_id}**：檢索研究輸出
- **WebSocket /ws**：即時進度更新

---

## 4. 研究工作流

### 4.1 簡易工作流

針對文獻基礎研究的循序執行：

1. 透過網路搜尋進行文獻蒐集
2. 論點提取與結構化
3. 大綱生成
4. 逐章撰寫
5. 編輯審閱與精煉
6. 引文格式化

### 4.2 增強工作流

包含品質保證機制：

1. 執行簡易工作流
2. 具評分功能的自動化審閱（1-10 量表）
3. 基於品質門檻的條件式修訂
4. 所有迭代的版本追蹤
5. 最終接受或優雅降級

### 4.3 領域適應工作流

針對不同學術領域的專業化處理：

**支援領域**：
- 資訊科學：強調演算法分析與實作
- 商業管理：聚焦個案研究與市場分析
- 醫療保健：整合臨床數據與實證實務
- 教育學：教學法框架分析
- 通用：平衡的跨領域方法

### 4.4 混合工作流

結合文獻回顧與計算數據分析：

1. 平行執行文獻蒐集與數據分析
2. 質性與量化發現的綜合
3. 含視覺化的整合報告
4. 文獻主張與實證數據的交叉驗證

---

## 5. 使用案例與應用

### 5.1 學術文獻回顧

**輸入**：研究主題（例：「氣候科學中的機器學習應用」）

**流程**：
- 文獻蒐集專家收集近期出版品與回顧文章
- 研究分析師提取關鍵發現與方法論
- 大綱規劃師依主題（演算法、資料集、結果）組織內容
- 學術寫作專家撰寫連貫敘事
- 引文格式化師生成參考書目

**輸出**：引用 50 筆以上來源的全面性文獻回顧

### 5.2 數據驅動研究報告

**輸入**：資料集（CSV/Excel）+ 分析目標

**流程**：
- 計算科學家載入與探索數據
- 統計分析與假設檢定
- 視覺化生成（相關矩陣、分布圖、趨勢圖）
- 於學術脈絡中詮釋發現
- 與相關文獻整合

**輸出**：含嵌入式視覺化與統計分析的研究報告

### 5.3 混合研究出版品

**輸入**：研究問題 + 資料集 + 領域規格

**流程**：
- 專案經理決定最佳策略
- 平行執行文獻回顧與數據分析
- 實證發現與理論框架的交叉引用
- 以領域特定格式進行全面性綜合
- 透過自動化審閱進行品質保證

**輸出**：可供發表的手稿，含摘要、緒論、方法、結果、討論與參考文獻

---

## 6. 品質保證與驗證

### 6.1 引用完整性

生成文本中的所有主張均透過內文引用連結至來源 URL。引文格式化師代理：

1. 從手稿中提取所有 URL 參考
2. 檢索元數據（作者、標題、出版日期、發行者）
3. 依據 APA 第七版標準格式化條目
4. 按字母排序並以標準參考文獻清單格式呈現

### 6.2 內容品質指標

編輯審閱師代理依多個面向評估草稿：

- **連貫性**：章節間的邏輯流暢（權重：25%）
- **學術嚴謹性**：適當的術語使用與論證（權重：25%）
- **完整性**：大綱要點的涵蓋程度（權重：20%）
- **寫作品質**：文法、風格、清晰度（權重：20%）
- **引用涵蓋度**：主張的適當註明（權重：10%）

**評分量表**：
- 9-10：優秀，可供發表
- 7-8：良好，接受小幅修訂
- 5-6：適當，需實質修訂
- 3-4：不佳，需重大重組
- 1-2：不可接受，需完全重寫

### 6.3 版本控制

所有工作流階段保存歷史版本：

```
results/session_20250105_143000/
├── draft_v1_score6.5_20250105_143200.txt
├── draft_v2_score7.8_20250105_143800.txt
├── final_report.txt
├── analysis_visualizations.png
└── metadata.json
```

---

## 7. 效能評估

### 7.1 計算效率

**平均執行時間**（Intel Xeon 16核心、32GB RAM）：

| 工作流類型 | 持續時間 | 代理呼叫次數 | API 成本 |
|-----------|---------|------------|---------|
| 簡易（文獻型） | 8-12 分鐘 | 25-30 | $0.50-0.80 |
| 增強（含審閱） | 15-20 分鐘 | 40-50 | $0.80-1.20 |
| 數據分析 | 5-10 分鐘 | 15-20 | $0.30-0.60 |
| 混合 | 20-30 分鐘 | 50-70 | $1.20-2.00 |

### 7.2 輸出品質評估

**指標**（基於 100 個測試研究任務）：

- 文獻檢索準確度：95% 相關來源
- 引用完整性：98% 主張適當註明
- APA 格式符合度：97% 正確格式化
- 手稿連貫性分數：平均 7.8/10
- 數據分析正確性：92% 有效統計詮釋

### 7.3 成本最佳化

**模型選擇影響**：

| 配置 | 成本/報告 | 品質分數 | 效率比 |
|-----|---------|---------|--------|
| 經濟型（全部 mini 模型） | $0.35 | 6.5/10 | 18.6 |
| 平衡型（混合層級） | $0.85 | 7.8/10 | 9.2 |
| 頂級型（全部旗艦模型） | $2.40 | 8.3/10 | 3.5 |

平衡型配置為多數使用案例提供最佳的成本品質權衡。

---

## 8. 限制與未來研究

### 8.1 目前限制

1. **語言支援**：目前實作針對英文與中文手稿最佳化
2. **領域涵蓋**：專業領域（例：進階數學）可能需要領域特定模型
3. **引用驗證**：元數據提取依賴來源可得性
4. **計算資源**：大型資料集分析受記憶體限制約束
5. **模型依賴**：品質繫結於底層 LLM 能力

### 8.2 規劃增強功能

**版本 3.2 路線圖**：
- 多語言支援（日文、韓文、西班牙文）
- 進階統計建模（時間序列、貝氏推論）
- 互動式數據視覺化儀表板
- LaTeX 輸出格式供學術投稿
- 與參考文獻管理系統整合（Zotero、Mendeley）

**版本 4.0 願景**：
- 跨機構研究協作聯盟
- 即時文獻監控與警示系統
- 從數據模式自動生成假設
- 與學術出版平台整合
- 同儕審查模擬與手稿改進建議

---

## 9. 倫理考量

### 9.1 學術誠信

Veritas 設計為研究輔助工具，非人類學術研究的替代品。使用者負責：

- 驗證所有生成內容的準確性
- 審查與驗證引用來源
- 添加原創見解與詮釋
- 於手稿致謝中揭露 AI 輔助

### 9.2 資料隱私

所有數據處理於本地進行。使用者上傳的資料集：
- 不傳輸至外部伺服器（API 呼叫除外）
- 於會話完成後自動刪除
- 遵循機構資料治理政策

### 9.3 API 使用合規

使用者必須維護自己的 API 憑證並遵守：
- OpenAI 服務條款
- Tavily API 可接受使用政策
- 適用的學術誠信準則

---

## 10. 技術文件

### 10.1 模組結構

```
veritas-ai-researcher/
├── agents.py                 # 代理定義與配置
├── tasks.py                  # 各代理的任務範本
├── tools.py                  # 自訂工具與整合
├── config.py                 # LLM 配置管理
├── api_server.py             # FastAPI Web 服務
├── workflows/                # LangGraph 工作流定義
│   ├── simple_workflow.py
│   ├── enhanced_workflow.py
│   ├── domain_adaptive_workflow.py
│   └── hybrid_workflow.py
├── frontend/                 # React 基礎 Web 介面
├── results/                  # 研究輸出目錄
├── uploads/                  # 使用者資料上傳目錄
└── requirements.txt          # Python 相依套件
```

### 10.2 配置選項

**LLM 模型選擇**：
```python
from config import LLMFactory

# 建立代理最佳化的 LLM
llm = LLMFactory.create_agent_llm("academic_writer")

# 建立預算導向的 LLM
llm = LLMFactory.create_budget_conscious_llm(
    "academic_writer",
    budget_tier="economy"
)

# 自訂模型覆寫
llm = LLMFactory.create_llm(
    "gpt-4o",
    temperature=0.7,
    max_tokens=4000
)
```

**工作流配置**：
```python
from workflows.enhanced_workflow import create_enhanced_workflow

# 以自訂參數建立工作流
workflow = create_enhanced_workflow(
    max_revisions=3,
    quality_threshold=8,
    enable_version_control=True
)

# 執行研究任務
result = workflow.run(
    goal="分析 AI 對醫療服務提供的影響",
    data_file_path="data/healthcare_metrics.csv"
)
```

### 10.3 擴充與自訂

**新增自訂代理**：
```python
from crewai import Agent
from config import LLMFactory

def custom_statistical_agent():
    llm = LLMFactory.create_llm("o3-mini")
    return Agent(
        role="統計顧問",
        goal="進階統計分析與驗證",
        backstory="具 20 年經驗的專家統計學家...",
        llm=llm,
        tools=[custom_r_executor_tool],
        verbose=True
    )
```

**新增自訂工具**：
```python
from crewai.tools import BaseTool

class CustomDatabaseTool(BaseTool):
    name: str = "DatabaseQuery"
    description: str = "對研究資料庫執行 SQL 查詢"

    def _run(self, query: str) -> str:
        # 實作
        return results
```

---

## 11. 測試與驗證

### 11.1 單元測試

```bash
# 執行核心功能測試
python -m pytest tests/

# 執行整合測試
python -m pytest tests/integration/

# 執行效能基準測試
python -m pytest tests/performance/
```

### 11.2 系統診斷

```bash
# 驗證安裝
python quick_diagnostic.py

# 測試 API 連線
python test_system.py

# 驗證回饋系統
python test_feedback_system.py
```

---

## 12. 貢獻

我們歡迎研究社群的貢獻。請遵循以下準則：

### 12.1 開發設定

```bash
# Fork 儲存庫
git clone https://github.com/YOUR_USERNAME/veritas-ai-researcher.git
cd veritas-ai-researcher

# 建立功能分支
git checkout -b feature/your-feature-name

# 安裝開發相依套件
pip install -r requirements.txt
pip install black isort pytest

# 執行程式碼格式化工具
black .
isort .

# 執行測試
pytest tests/
```

### 12.2 程式碼標準

- 遵循 PEP 8 風格指南
- 為所有函式加入型別提示
- 以 Google 風格撰寫文件字串
- 維持測試涵蓋率 80% 以上
- 文件化所有公開 API

### 12.3 Pull Request 流程

1. 為任何新功能更新文件
2. 為新功能添加單元測試
3. 確保所有測試於本地通過
4. 提交含詳細描述的 PR
5. 回應審查者回饋

---

## 13. 授權

本專案採用 MIT 授權條款。詳見 LICENSE 檔案。

```
MIT License

Copyright (c) 2025 Veritas Research Platform

茲此授予任何取得本軟體及相關文件檔案（「本軟體」）複本之人士，
不受限制地處理本軟體之權利，包括但不限於使用、複製、修改、
合併、發布、散布、再授權及／或販售本軟體複本之權利，
且准許獲提供本軟體之人士依下列條件享有上述權利：

上述著作權聲明及本許可聲明須包含於本軟體所有複本或
重要部分中。

本軟體係依「現況」提供，不附帶任何明示或暗示之保證，
包括但不限於適售性、特定目的適用性及非侵權之保證。
於任何情況下，著作人或著作權持有人對於因本軟體或
本軟體之使用或其他處理所產生、引致或與其有關之
任何索賠、損害或其他責任，無論其係因契約、侵權
或其他原因產生，概不負責。
```

---

## 14. 致謝

本研究平台建構於數個開源專案與商業 API 之上：

- **CrewAI**：多代理協調框架（https://crewai.com）
- **LangChain**：LLM 應用開發框架（https://langchain.com）
- **OpenAI**：大型語言模型 API（https://openai.com）
- **Tavily**：智能搜尋 API（https://tavily.com）

我們感謝開源社群對 Python 科學計算生態系統的貢獻，包括 pandas、numpy、matplotlib、seaborn 與 scikit-learn 的開發者。

---

## 15. 引用

若您於研究中使用 Veritas，請引用：

```bibtex
@software{veritas2025,
  author = {Veritas Research Platform Contributors},
  title = {Veritas：基於多代理架構的自動化學術研究框架},
  year = {2025},
  version = {3.1.0},
  url = {https://github.com/jaywang172/veritas-ai-researcher},
  note = {運用多代理 LLM 協調的自主式研究輔助系統}
}
```

---

## 16. 聯絡與支援

### 16.1 問題回報

針對錯誤回報與功能請求，請使用 GitHub 問題追蹤器：
https://github.com/jaywang172/veritas-ai-researcher/issues

### 16.2 文件

完整文件請見：[文件 URL]

### 16.3 社群

- GitHub 討論區：供一般問題與社群支援
- 專案 Wiki：供教學與進階使用指南

---

## 17. 版本歷史

### 版本 3.1.0（目前版本）
- 實作具品質評分功能的自動化審閱循環
- 新增所有研究產出物的全面版本控制
- 引入針對專業研究領域的領域適應工作流
- 增強具元數據提取功能的引文格式化
- 最佳化 LLM 配置以平衡成本效能

### 版本 3.0.0
- 完整架構重新設計，整合 LangGraph
- 具專業化角色的八代理系統
- 網路基礎前端介面
- 透過 WebSocket 的即時進度監控
- 支援混合文獻-數據研究

### 版本 2.x
- 基礎多代理實作
- 循序工作流處理
- 僅命令列介面

---

## 附錄 A：配置參考

### A.1 支援的 LLM 模型

| 模型 | 脈絡視窗 | 最大輸出 | 使用案例 |
|-----|---------|---------|---------|
| gpt-5 | 128K 詞元 | 16K 詞元 | 頂級編輯 |
| gpt-5-mini | 128K 詞元 | 16K 詞元 | 進階寫作 |
| gpt-4.1 | 128K 詞元 | 4K 詞元 | 可靠的工具使用 |
| gpt-4.1-mini | 128K 詞元 | 4K 詞元 | 平衡任務 |
| gpt-4o | 128K 詞元 | 4K 詞元 | 多模態輸入 |
| gpt-4o-mini | 128K 詞元 | 4K 詞元 | 成本效益搜尋 |
| o3 | 200K 詞元 | 100K 詞元 | 複雜推理 |
| o3-mini | 200K 詞元 | 64K 詞元 | 策略規劃 |

### A.2 API 速率限制

預設配置遵守 API 提供者限制：
- OpenAI：10,000 請求/分鐘（第 3 層）
- Tavily：1,000 搜尋/月（免費層）

針對正式環境部署，建議企業層訂閱。

---

## 附錄 B：疑難排解

### B.1 常見問題

**問題**：模組匯入錯誤
**解決方案**：驗證虛擬環境已啟動並執行 `pip install -r requirements.txt`

**問題**：API 認證失敗
**解決方案**：驗證 `.env` 檔案包含所有服務的有效憑證

**問題**：數據分析時記憶體不足
**解決方案**：縮減資料集大小或增加系統 RAM 配置

**問題**：工作流執行緩慢
**解決方案**：檢查 API 端點的網路延遲，考慮區域性 API 端點

### B.2 診斷指令

```bash
# 檢查 Python 版本
python --version

# 驗證相依套件
python -c "import pandas, crewai, langgraph; print('所有匯入成功')"

# 測試 API 連線
python test_system.py

# 檢查系統資源
python quick_diagnostic.py
```

---

**文件版本**：1.0
**最後更新**：2025-01-05
**維護說明**：本文件隨各軟體發行版本積極維護與更新。
