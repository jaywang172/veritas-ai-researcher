#!/usr/bin/env python3
"""
æµ‹è¯• Veritas LLM é…ç½®ç³»ç»Ÿ
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥configæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# æ¨¡æ‹Ÿ langchain_openai.ChatOpenAI
class MockChatOpenAI:
    def __init__(self, model="gpt-4", temperature=0.1, **kwargs):
        self.model_name = model
        self.temperature = temperature
        self.kwargs = kwargs
    
    def __repr__(self):
        return f"MockChatOpenAI(model={self.model_name}, temperature={self.temperature})"

# æ›¿æ¢åŸå§‹å¯¼å…¥
import config
config.ChatOpenAI = MockChatOpenAI

def test_llm_configurations():
    """æµ‹è¯•LLMé…ç½®ç³»ç»Ÿ"""
    print("ğŸ§ª Veritas v2.0 LLMé…ç½®ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®ä¿¡æ¯å±•ç¤º
    config.print_llm_configuration()
    
    # æµ‹è¯•é¢„ç®—æ¯”è¾ƒ
    config.print_budget_comparison()
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("\nğŸ”§ æ¨¡å‹åˆ›å»ºæµ‹è¯•:")
    print("-" * 40)
    
    for agent_type in ["literature_scout", "academic_writer", "editor"]:
        try:
            llm = config.LLMFactory.create_agent_llm(agent_type)
            config_name = config.AGENT_LLM_MAPPING[agent_type]
            tier = config.LLM_CONFIGS[config_name].tier.value
            print(f"âœ… {agent_type:<18}: {llm.model_name} ({tier} tier)")
        except Exception as e:
            print(f"âŒ {agent_type:<18}: Error - {e}")
    
    # æµ‹è¯•é¢„ç®—å‹å¥½é…ç½®
    print("\nğŸ’° é¢„ç®—çº§åˆ«æµ‹è¯•:")
    print("-" * 40)
    
    for tier in ["economy", "balanced", "premium"]:
        try:
            llm = config.LLMFactory.create_budget_conscious_llm("academic_writer", tier)
            print(f"âœ… {tier:<10} writer: {llm.model_name}")
        except Exception as e:
            print(f"âŒ {tier:<10} writer: Error - {e}")
    
    # æµ‹è¯•æˆæœ¬åˆ†æ
    print("\nğŸ“Š æˆæœ¬åˆ†ææµ‹è¯•:")
    print("-" * 40)
    
    for model_name in ["gpt-3.5-turbo", "gpt-4.1", "gpt-4-turbo"]:
        cost = config.LLMFactory.estimate_cost(model_name, 1000)
        model_info = config.LLMFactory.get_model_info(model_name)
        tier = model_info.get('tier', 'unknown')
        print(f"ğŸ“ˆ {model_name:<15}: ${cost:.4f}/1K tokens ({tier})")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("ğŸ¯ Veritas ç°åœ¨æ˜¯çœŸæ­£çš„ã€Œæ¨¡å‹æ— å…³ã€æ™ºèƒ½å¹³å°ï¼")
    print("=" * 60)

if __name__ == "__main__":
    test_llm_configurations()
