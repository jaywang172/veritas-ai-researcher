#!/usr/bin/env python3
"""
Veritas Hybrid Intelligence Workflow
LangGraph-based state machine for autonomous research planning and execution.
"""

import json
from typing import Dict, List, Optional, TypedDict, Annotated
from pathlib import Path
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, AIMessage

# Import our agents and tasks
from agents import (
    project_manager, literature_scout, synthesizer, outline_planner,
    academic_writer, editor, citation_formatter, computational_scientist
)
from tasks import (
    create_research_task, create_summarize_task, create_outline_task,
    create_writing_task, create_review_task, create_citation_task,
    create_data_analysis_task
)
from crewai import Crew, Process
from datetime import datetime


# ğŸ†• ç‰ˆæœ¬æ§åˆ¶èˆ‡æ­·å²è¿½è¹¤è¼”åŠ©å‡½æ•¸
def save_version_to_history(state: 'ResearchState', content: str, version_type: str, description: str = "") -> None:
    """
    å°‡ç•¶å‰ç‰ˆæœ¬ä¿å­˜åˆ°æ­·å²è¨˜éŒ„ä¸­
    
    Args:
        state: ç ”ç©¶ç‹€æ…‹
        content: è¦ä¿å­˜çš„å…§å®¹
        version_type: ç‰ˆæœ¬é¡å‹ (draft, revised, final)
        description: ç‰ˆæœ¬æè¿°
    """
    if not state.get('version_history'):
        state['version_history'] = []
    
    current_version = state.get('current_version', 0) + 1
    state['current_version'] = current_version
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    version_record = {
        'version': current_version,
        'timestamp': timestamp,
        'type': version_type,
        'description': description,
        'content': content,
        'revision_count': state.get('revision_count', 0),
        'review_score': state.get('review_score'),
        'word_count': len(content.split()) if content else 0
    }
    
    state['version_history'].append(version_record)
    
    # å¦‚æœå•Ÿç”¨è‡ªå‹•ä¿å­˜ï¼Œå‰µå»ºæª”æ¡ˆ
    if state.get('auto_save_enabled', True):
        try:
            safe_goal = "".join(c for c in state['research_goal'] if c.isalnum() or c in (' ', '-', '_')).strip()
            filename = f"veritas_v{current_version:02d}_{version_type}_{safe_goal[:20]}.txt"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# Veritas v3.1 - ç‰ˆæœ¬ {current_version} ({version_type})\n")
                f.write(f"# æ™‚é–“æˆ³ï¼š{timestamp}\n")
                f.write(f"# ä¿®è¨‚æ¬¡æ•¸ï¼š{state.get('revision_count', 0)}\n")
                f.write(f"# è©•åˆ†ï¼š{state.get('review_score', 'N/A')}/10\n")
                f.write(f"# æè¿°ï¼š{description}\n")
                f.write(f"# å­—æ•¸ï¼š{len(content.split())} å­—\n")
                f.write(f"{'='*60}\n\n")
                f.write(content)
            
            print(f"ç‰ˆæœ¬ v{current_version} å·²è‡ªå‹•ä¿å­˜ï¼š{filename}")
            
        except Exception as e:
            print(f"è‡ªå‹•ä¿å­˜å¤±æ•—ï¼š{e}")


def get_latest_version_content(state: 'ResearchState') -> Optional[str]:
    """ç²å–æœ€æ–°ç‰ˆæœ¬çš„å…§å®¹"""
    version_history = state.get('version_history', [])
    if version_history:
        return version_history[-1].get('content')
    return None


def format_revision_history_summary(state: 'ResearchState') -> str:
    """æ ¼å¼åŒ–ä¿®è¨‚æ­·å²æ‘˜è¦ï¼Œç”¨æ–¼å±•ç¤ºçµ¦ç”¨æˆ¶"""
    revision_history = state.get('revision_history', [])
    if not revision_history:
        return "ç„¡ä¿®è¨‚æ­·å²"
    
    summary = "## ğŸ”„ ä¿®è¨‚æ­·å²æ‘˜è¦\n\n"
    for i, record in enumerate(revision_history, 1):
        decision = record.get('decision', 'UNKNOWN')
        score = record.get('quality_score', 'N/A')
        priority = record.get('revision_priority', 'N/A')
        feedback = record.get('feedback', '')[:100] + "..." if len(record.get('feedback', '')) > 100 else record.get('feedback', '')
        
        summary += f"### ç¬¬ {i} è¼ªå¯©æ ¸\n"
        summary += f"- **æ±ºç­–**ï¼š{decision}\n"
        summary += f"- **è©•åˆ†**ï¼š{score}/10\n"
        summary += f"- **å„ªå…ˆç´š**ï¼š{priority}\n"
        summary += f"- **åé¥‹**ï¼š{feedback}\n\n"
    
    return summary


class ResearchState(TypedDict):
    """
    æ··åˆç ”ç©¶å·¥ä½œæµç¨‹çš„ç‹€æ…‹å®šç¾©
    åŒ…å«æ•´å€‹ç ”ç©¶éç¨‹ä¸­éœ€è¦å…±äº«çš„æ‰€æœ‰è³‡è¨Š
    
    v3.1 å‡ç´šï¼šå¼•å…¥ç‰ˆæœ¬æ§åˆ¶èˆ‡æ™ºèƒ½å¯©ç¨¿è¿´åœˆ
    """
    # è¼¸å…¥è³‡è¨Š
    research_goal: str                          # ä½¿ç”¨è€…çš„ç ”ç©¶ç›®æ¨™
    data_file_path: Optional[str]              # å¯é¸çš„è³‡æ–™æª”æ¡ˆè·¯å¾‘
    
    # å°ˆæ¡ˆè¦åŠƒ
    project_plan: Optional[Dict]               # å°ˆæ¡ˆç¶“ç†çš„ç­–ç•¥è¦åŠƒ
    
    # æ–‡ç»ç ”ç©¶çµæœ
    literature_data: Optional[str]             # åŸå§‹æ–‡ç»æœé›†è³‡æ–™
    literature_points: Optional[List[Dict]]    # æå–çš„æ–‡ç»è«–é»
    
    # æ•¸æ“šåˆ†æçµæœ
    data_analysis_results: Optional[str]       # æ•¸æ“šåˆ†ææ‘˜è¦
    data_analysis_points: Optional[List[Dict]] # æ ¼å¼åŒ–çš„åˆ†æè«–é»
    
    # æ•´åˆèˆ‡å¯«ä½œ
    combined_points: Optional[List[Dict]]      # æ•´åˆçš„è«–é»åˆ—è¡¨
    outline_data: Optional[Dict]               # è«–æ–‡å¤§ç¶±
    draft_content: Optional[str]               # åˆç¨¿å…§å®¹
    final_paper_content: Optional[str]         # ç·¨è¼¯å¾Œçš„è«–æ–‡
    complete_paper_content: Optional[str]      # åŒ…å«å¼•æ–‡çš„å®Œæ•´è«–æ–‡
    
    # ğŸ†• ç‰ˆæœ¬æ§åˆ¶èˆ‡æ­·å²è¿½è¹¤
    version_history: List[Dict]                # æ‰€æœ‰ç‰ˆæœ¬çš„å®Œæ•´æ­·å²
    current_version: int                       # ç•¶å‰ç‰ˆæœ¬è™Ÿ
    auto_save_enabled: bool                    # æ˜¯å¦å•Ÿç”¨è‡ªå‹•ç‰ˆæœ¬å„²å­˜
    
    # ğŸ†• æ™ºèƒ½å“è³ªå¯©æ ¸ç³»çµ±
    review_decision: Optional[str]             # å¯©æ ¸æ±ºç­–ï¼šACCEPT/REVISE/REJECT
    review_feedback: Optional[str]             # è©³ç´°çš„å¯©æ ¸æ„è¦‹å’Œä¿®æ”¹å»ºè­°
    review_score: Optional[int]                # å“è³ªè©•åˆ† (1-10)
    review_priority: Optional[str]             # ä¿®è¨‚å„ªå…ˆç´šï¼šHIGH/MEDIUM/LOW
    specific_issues: List[str]                 # å…·é«”å•é¡Œæ¸…å–®
    
    # ğŸ†• ä¿®è¨‚è¿´åœˆæ§åˆ¶
    revision_count: int                        # ä¿®è¨‚æ¬¡æ•¸è¨ˆæ•¸å™¨
    max_revisions: int                         # æœ€å¤§ä¿®è¨‚æ¬¡æ•¸é™åˆ¶
    revision_history: List[Dict]               # è©³ç´°ä¿®è¨‚æ­·å²è¨˜éŒ„
    quality_gates_passed: List[str]           # å·²é€šéçš„å“è³ªé—œå¡
    is_in_revision_loop: bool                  # æ˜¯å¦è™•æ–¼ä¿®è¨‚è¿´åœˆä¸­
    last_revision_timestamp: Optional[str]    # æœ€å¾Œä¿®è¨‚æ™‚é–“æˆ³
    
    # ğŸ†• å¤±æ•—ä¿è­·èˆ‡æœ€çµ‚è£æ±º
    force_accept_reason: Optional[str]         # å¼·åˆ¶æ¥å—çš„åŸå› 
    workflow_completion_status: str           # å·¥ä½œæµç¨‹å®Œæˆç‹€æ…‹
    final_decision_maker: Optional[str]        # æœ€çµ‚æ±ºç­–è€… (AI/HUMAN/SYSTEM)
    
    # å·¥ä½œæµç¨‹ç‹€æ…‹
    tasks_completed: List[str]                 # å·²å®Œæˆçš„ä»»å‹™åˆ—è¡¨
    current_stage: str                         # ç›®å‰åŸ·è¡Œéšæ®µ
    errors: List[str]                          # éŒ¯èª¤è¨˜éŒ„
    
    # LangGraph éœ€è¦çš„è¨Šæ¯ç‹€æ…‹
    messages: Annotated[List[Dict], "è¨Šæ¯æ­·å²"]


def project_planning_node(state: ResearchState) -> ResearchState:
    """
    å°ˆæ¡ˆè¦åŠƒç¯€é»ï¼šç”±å°ˆæ¡ˆç¶“ç†åˆ†æç›®æ¨™ä¸¦åˆ¶å®šåŸ·è¡Œç­–ç•¥
    """
    print("\n=== å°ˆæ¡ˆè¦åŠƒéšæ®µ ===")
    print(f"ç ”ç©¶ç›®æ¨™ï¼š{state['research_goal']}")
    if state.get('data_file_path'):
        print(f"è³‡æ–™æª”æ¡ˆï¼š{state['data_file_path']}")
    
    # æ§‹å»ºå°ˆæ¡ˆç¶“ç†çš„åˆ†ææç¤º
    planning_prompt = f"""
    ä½œç‚ºé¦–å¸­ç ”ç©¶ç­–ç•¥å¸«ï¼Œè«‹åˆ†æä»¥ä¸‹ç ”ç©¶è«‹æ±‚ä¸¦åˆ¶å®šåŸ·è¡Œç­–ç•¥ï¼š
    
    ç ”ç©¶ç›®æ¨™ï¼š{state['research_goal']}
    è³‡æ–™æª”æ¡ˆï¼š{state.get('data_file_path', 'ç„¡')}
    
    è«‹åˆ†æä¸¦æ±ºå®šï¼š
    1. é€™å€‹ç ”ç©¶éœ€è¦ä»€éº¼é¡å‹çš„åˆ†æï¼ˆæ–‡ç»å›é¡§ã€æ•¸æ“šåˆ†æã€æˆ–å…©è€…çµåˆï¼‰
    2. æ‡‰è©²æŒ‰ä»€éº¼é †åºåŸ·è¡Œä»»å‹™
    3. å“ªäº›å°ˆå®¶ä»£ç†äººéœ€è¦åƒèˆ‡
    
    è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
    {{
        "research_type": "LITERATURE_ONLY/DATA_ONLY/HYBRID",
        "requires_literature": true/false,
        "requires_data_analysis": true/false,
        "execution_strategy": "SEQUENTIAL/PARALLEL",
        "priority_tasks": ["task1", "task2", ...],
        "reasoning": "æ±ºç­–ç†ç”±"
    }}
    """
    
    try:
        # è®“å°ˆæ¡ˆç¶“ç†åˆ†æä¸¦è¦åŠƒ
        from crewai import Task
        
        planning_task = Task(
            description=planning_prompt,
            expected_output="JSONæ ¼å¼çš„å°ˆæ¡ˆè¦åŠƒ",
            agent=project_manager
        )
        
        planning_crew = Crew(
            agents=[project_manager],
            tasks=[planning_task],
            verbose=False
        )
        
        planning_result = planning_crew.kickoff()
        
        if planning_result and planning_result.raw:
            try:
                # å˜—è©¦è§£æJSONå›æ‡‰
                plan_text = planning_result.raw
                # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœè¢«åŒ…è£åœ¨å…¶ä»–æ–‡å­—ä¸­ï¼‰
                if '{' in plan_text and '}' in plan_text:
                    json_start = plan_text.find('{')
                    json_end = plan_text.rfind('}') + 1
                    json_text = plan_text[json_start:json_end]
                    project_plan = json.loads(json_text)
                else:
                    # å¦‚æœæ²’æœ‰JSONï¼Œå‰µå»ºé»˜èªè¨ˆåŠƒ
                    project_plan = {
                        "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
                        "requires_literature": True,
                        "requires_data_analysis": bool(state.get('data_file_path')),
                        "execution_strategy": "PARALLEL",
                        "priority_tasks": ["literature_research", "data_analysis"] if state.get('data_file_path') else ["literature_research"],
                        "reasoning": "åŸºæ–¼è¼¸å…¥è‡ªå‹•åˆ¤æ–·"
                    }
                
                print(f"å°ˆæ¡ˆè¦åŠƒå®Œæˆï¼š{project_plan['research_type']}")
                print(f"åŸ·è¡Œç­–ç•¥ï¼š{project_plan['execution_strategy']}")
                
                state['project_plan'] = project_plan
                state['current_stage'] = 'planning_completed'
                state['tasks_completed'].append('project_planning')
                
            except json.JSONDecodeError:
                print("ç„¡æ³•è§£æå°ˆæ¡ˆè¦åŠƒJSONï¼Œä½¿ç”¨é»˜èªç­–ç•¥")
                state['project_plan'] = {
                    "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
                    "requires_literature": True,
                    "requires_data_analysis": bool(state.get('data_file_path')),
                    "execution_strategy": "PARALLEL",
                    "priority_tasks": ["literature_research"],
                    "reasoning": "JSONè§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨ç­–ç•¥"
                }
        else:
            print("å°ˆæ¡ˆè¦åŠƒå¤±æ•—ï¼Œä½¿ç”¨é»˜èªç­–ç•¥")
            state['errors'].append("å°ˆæ¡ˆè¦åŠƒç¯€é»åŸ·è¡Œå¤±æ•—")
    
    except Exception as e:
        print(f"å°ˆæ¡ˆè¦åŠƒéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å°ˆæ¡ˆè¦åŠƒéŒ¯èª¤ï¼š{str(e)}")
        # ä½¿ç”¨å‚™ç”¨ç­–ç•¥
        state['project_plan'] = {
            "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
            "requires_literature": True,
            "requires_data_analysis": bool(state.get('data_file_path')),
            "execution_strategy": "SEQUENTIAL",
            "priority_tasks": ["literature_research"],
            "reasoning": "éŒ¯èª¤æ¢å¾©ç­–ç•¥"
        }
        state['current_stage'] = 'planning_completed'
        state['tasks_completed'].append('project_planning')
    
    return state


def literature_research_node(state: ResearchState) -> ResearchState:
    """
    æ–‡ç»ç ”ç©¶ç¯€é»ï¼šæœé›†ä¸¦åˆ†æå¤–éƒ¨æ–‡ç»è³‡æ–™
    """
    print("\n=== æ–‡ç»ç ”ç©¶éšæ®µ ===")
    
    try:
        # éšæ®µä¸€ï¼šæ–‡ç»æœé›†
        research_task = create_research_task(state['research_goal'])
        research_crew = Crew(
            agents=[literature_scout],
            tasks=[research_task],
            verbose=False
        )
        
        literature_result = research_crew.kickoff()
        if literature_result and literature_result.raw:
            state['literature_data'] = literature_result.raw
            print("æ–‡ç»æœé›†å®Œæˆ")
        else:
            state['errors'].append("æ–‡ç»æœé›†å¤±æ•—")
            return state
        
        # éšæ®µäºŒï¼šè«–é»æå–
        summarize_task = create_summarize_task()
        summarize_task.context = [research_task]
        
        synthesis_crew = Crew(
            agents=[synthesizer],
            tasks=[summarize_task],
            verbose=False
        )
        
        synthesis_result = synthesis_crew.kickoff()
        if synthesis_result and synthesis_result.raw:
            try:
                points_data = json.loads(synthesis_result.raw)
                state['literature_points'] = points_data
                print(f"æ–‡ç»è«–é»æå–å®Œæˆï¼š{len(points_data)} å€‹è«–é»")
            except json.JSONDecodeError:
                print("æ–‡ç»è«–é»JSONæ ¼å¼éŒ¯èª¤")
                state['errors'].append("æ–‡ç»è«–é»è§£æå¤±æ•—")
        else:
            state['errors'].append("æ–‡ç»è«–é»æå–å¤±æ•—")
        
        state['tasks_completed'].append('literature_research')
        
    except Exception as e:
        print(f"æ–‡ç»ç ”ç©¶éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ–‡ç»ç ”ç©¶éŒ¯èª¤ï¼š{str(e)}")
    
    return state


def data_analysis_node(state: ResearchState) -> ResearchState:
    """
    æ•¸æ“šåˆ†æç¯€é»ï¼šåŸ·è¡Œæœ¬åœ°æ•¸æ“šåˆ†æ
    """
    print("\nğŸ“Š === æ•¸æ“šåˆ†æéšæ®µ ===")
    
    if not state.get('data_file_path'):
        print("ç„¡æ•¸æ“šæª”æ¡ˆï¼Œè·³éæ•¸æ“šåˆ†æ")
        return state
    
    try:
        analysis_task = create_data_analysis_task(
            state['data_file_path'], 
            state['research_goal']
        )
        
        analysis_crew = Crew(
            agents=[computational_scientist],
            tasks=[analysis_task],
            verbose=False
        )
        
        analysis_result = analysis_crew.kickoff()
        
        if analysis_result and analysis_result.raw:
            state['data_analysis_results'] = analysis_result.raw
            
            # å°‡æ•¸æ“šåˆ†æçµæœæ ¼å¼åŒ–ç‚ºè«–é»
            analysis_point = {
                "sentence": analysis_result.raw,
                "source": f"æœ¬åœ°æ•¸æ“šåˆ†æï¼š{state['data_file_path']}"
            }
            state['data_analysis_points'] = [analysis_point]
            
            print("æ•¸æ“šåˆ†æå®Œæˆ")
            state['tasks_completed'].append('data_analysis')
        else:
            state['errors'].append("æ•¸æ“šåˆ†æåŸ·è¡Œå¤±æ•—")
            # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
            state['tasks_completed'].append('data_analysis')
            # æä¾›å‚™ç”¨åˆ†æçµæœ
            state['data_analysis_points'] = [{
                "sentence": "æ•¸æ“šåˆ†æåŸ·è¡Œå¤±æ•—ï¼Œç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„åˆ†æçµæœã€‚å»ºè­°æª¢æŸ¥æ•¸æ“šæ–‡ä»¶å’Œåˆ†æå·¥å…·é…ç½®ã€‚",
                "source": "æœ¬åœ°æ•¸æ“šåˆ†æ"
            }]
    
    except Exception as e:
        print(f"æ•¸æ“šåˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ•¸æ“šåˆ†æéŒ¯èª¤ï¼š{str(e)}")
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('data_analysis')
        # æä¾›å‚™ç”¨åˆ†æçµæœ
        state['data_analysis_points'] = [{
            "sentence": f"æ•¸æ“šåˆ†æéç¨‹é‡åˆ°æŠ€è¡“å•é¡Œï¼š{str(e)}ã€‚å»ºè­°æ‰‹å‹•æª¢æŸ¥æ•¸æ“šæ–‡ä»¶æ ¼å¼å’Œå…§å®¹ã€‚",
            "source": "æœ¬åœ°æ•¸æ“šåˆ†æ"
        }]
    
    return state


def integration_node(state: ResearchState) -> ResearchState:
    """
    æ•´åˆç¯€é»ï¼šçµåˆæ–‡ç»å’Œæ•¸æ“šåˆ†æçµæœï¼Œç”Ÿæˆçµ±ä¸€å¤§ç¶±
    """
    print("\nğŸ”„ === æ•´åˆèˆ‡è¦åŠƒéšæ®µ ===")
    
    try:
        # æ•´åˆæ‰€æœ‰è«–é»
        combined_points = []
        
        if state.get('literature_points'):
            combined_points.extend(state['literature_points'])
            print(f"æ•´åˆæ–‡ç»è«–é»ï¼š{len(state['literature_points'])} å€‹")
        
        if state.get('data_analysis_points'):
            combined_points.extend(state['data_analysis_points'])
            print(f"æ•´åˆæ•¸æ“šåˆ†æè«–é»ï¼š{len(state['data_analysis_points'])} å€‹")
        
        state['combined_points'] = combined_points
        
        if not combined_points:
            state['errors'].append("æ²’æœ‰è«–é»å¯ä¾›æ•´åˆ")
            return state
        
        # ç”Ÿæˆçµ±ä¸€å¤§ç¶±
        outline_task = create_outline_task()
        
        # å‰µå»ºè™›æ“¬çš„contextä»»å‹™ä¾†å‚³éè«–é»è³‡æ–™
        from crewai import Task
        context_task = Task(
            description="Combined research points",
            expected_output="Research points for outline generation",
            agent=synthesizer
        )
        context_task.output = type('MockOutput', (), {
            'raw': json.dumps(combined_points, ensure_ascii=False, indent=2)
        })()
        
        outline_task.context = [context_task]
        
        outline_crew = Crew(
            agents=[outline_planner],
            tasks=[outline_task],
            verbose=False
        )
        
        outline_result = outline_crew.kickoff()
        
        if outline_result and outline_result.raw:
            try:
                outline_data = json.loads(outline_result.raw)
                state['outline_data'] = outline_data
                print(f"å¤§ç¶±ç”Ÿæˆå®Œæˆï¼š{outline_data.get('title', 'æœªçŸ¥æ¨™é¡Œ')}")
                state['tasks_completed'].append('integration')
            except json.JSONDecodeError:
                print("å¤§ç¶±JSONæ ¼å¼éŒ¯èª¤")
                state['errors'].append("å¤§ç¶±è§£æå¤±æ•—")
        else:
            state['errors'].append("å¤§ç¶±ç”Ÿæˆå¤±æ•—")
    
    except Exception as e:
        print(f"æ•´åˆéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ•´åˆéŒ¯èª¤ï¼š{str(e)}")
    
    return state


def writing_node(state: ResearchState) -> ResearchState:
    """
    å¯«ä½œç¯€é»ï¼šæ ¹æ“šå¤§ç¶±å’Œè«–é»ç”Ÿæˆè«–æ–‡åˆç¨¿
    """
    print("\n=== å¯«ä½œéšæ®µ ===")
    
    if not state.get('outline_data') or not state.get('combined_points'):
        state['errors'].append("ç¼ºå°‘å¤§ç¶±æˆ–è«–é»è³‡æ–™")
        return state
    
    try:
        outline_data = state['outline_data']
        all_points = state['combined_points']
        
        draft_content = f"# {outline_data.get('title', 'ç ”ç©¶å ±å‘Š')}\n\n"
        
        for chapter in outline_data.get("chapters", []):
            chapter_title = chapter.get("chapter_title", "æœªå‘½åç« ç¯€")
            indices = chapter.get("supporting_points_indices", [])
            
            # ç²å–è©²ç« ç¯€çš„è«–é»
            chapter_points = [all_points[i] for i in indices if i < len(all_points)]
            
            print(f"å¯«ä½œç« ç¯€ï¼š{chapter_title}")
            
            writing_task = create_writing_task(
                chapter_title, 
                json.dumps(chapter_points, ensure_ascii=False, indent=2)
            )
            
            writing_crew = Crew(
                agents=[academic_writer],
                tasks=[writing_task],
                verbose=False
            )
            
            chapter_result = writing_crew.kickoff()
            
            if chapter_result and chapter_result.raw:
                chapter_content = chapter_result.raw
            else:
                chapter_content = "[ç« ç¯€å…§å®¹ç”Ÿæˆå¤±æ•—]"
            
            draft_content += f"## {chapter_title}\n\n{chapter_content}\n\n"
        
        state['draft_content'] = draft_content
        
        # ğŸ†• ç‰ˆæœ¬æ§åˆ¶ï¼šä¿å­˜åˆç¨¿
        save_version_to_history(
            state, 
            draft_content, 
            "draft", 
            "AIåœ˜éšŠå”ä½œç”Ÿæˆçš„åˆç¨¿"
        )
        
        print("åˆç¨¿æ’°å¯«å®Œæˆ")
        state['tasks_completed'].append('writing')
    
    except Exception as e:
        print(f"å¯«ä½œéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å¯«ä½œéŒ¯èª¤ï¼š{str(e)}")
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('writing')
        state['draft_content'] = f"# ç ”ç©¶å ±å‘Š\n\nç”±æ–¼æŠ€è¡“å•é¡Œï¼Œå¯«ä½œéç¨‹æœªèƒ½å®Œæˆã€‚éŒ¯èª¤ï¼š{str(e)}\n\nè«‹æª¢æŸ¥é…ç½®ä¸¦é‡è©¦ã€‚"
    
    return state


def editing_node(state: ResearchState) -> ResearchState:
    """
    ç·¨è¼¯ç¯€é»ï¼šå°ˆæ¥­ç·¨è¼¯å¯©é–±å’Œæ½¤è‰²
    """
    print("\n=== ç·¨è¼¯å¯©é–±éšæ®µ ===")
    
    if not state.get('draft_content'):
        state['errors'].append("æ²’æœ‰åˆç¨¿å¯ä¾›ç·¨è¼¯")
        return state
    
    try:
        from crewai import Task
        
        # ç›´æ¥å‰µå»ºåŒ…å«å®Œæ•´å…§å®¹çš„ç·¨è¼¯ä»»å‹™
        review_task = Task(
            description=f'''é€™æ˜¯è«–æ–‡çš„å®Œæ•´åˆç¨¿ï¼š

{state['draft_content']}

**ä½ çš„ç·¨è¼¯ä»»å‹™**ï¼š
1. **é€šè®€å…¨æ–‡**ï¼šä»”ç´°å¯©é–±æ•´ç¯‡è«–æ–‡ï¼Œè­˜åˆ¥ä¸¦ä¿®æ­£ä»»ä½•ä¸é€£è²«æˆ–çŸ›ç›¾ä¹‹è™•
2. **ç« ç¯€éæ¸¡**ï¼šç¢ºä¿æ‰€æœ‰ç« ç¯€ä¹‹é–“çš„éæ¸¡è‡ªç„¶æµæš¢ï¼Œå¿…è¦æ™‚æ·»åŠ æˆ–é‡å¯«éæ¸¡æ®µè½
3. **é¢¨æ ¼çµ±ä¸€**ï¼šçµ±ä¸€å…¨æ–‡çš„è¡“èªã€å¯«ä½œé¢¨æ ¼å’Œèªèª¿ï¼Œç¢ºä¿ä¸€è‡´æ€§
4. **é‚è¼¯æª¢æŸ¥**ï¼šé©—è­‰è«–è¿°é‚è¼¯çš„å®Œæ•´æ€§ï¼Œç¢ºä¿è«–é»ä¹‹é–“çš„é—œè¯æ€§æ¸…æ™°
5. **æ‘˜è¦ç”Ÿæˆ**ï¼šæ ¹æ“šå…¨æ–‡æ ¸å¿ƒå…§å®¹ï¼Œåœ¨æ–‡ç« æœ€é–‹é ­ç”Ÿæˆä¸€æ®µ 150-250 å­—çš„å°ˆæ¥­æ‘˜è¦

**æ ¼å¼è¦æ±‚**ï¼š
- åœ¨æ–‡ç« æœ€é–‹å§‹æ·»åŠ  "## æ‘˜è¦ (Abstract)" éƒ¨åˆ†
- ä¿æŒæ‰€æœ‰ç¾æœ‰çš„ä¾†æºæ¨™è¨»
- ä¿æŒç« ç¯€çµæ§‹ï¼Œä½†å¯ä»¥èª¿æ•´å…§å®¹å’Œéæ¸¡
- ç¢ºä¿æ‘˜è¦ç°¡æ½”ä¸”æ¦‚æ‹¬äº†è«–æ–‡çš„ä¸»è¦è²¢ç»''',
            expected_output='''ä¸€ä»½ç¶“éå°ˆæ¥­ç·¨è¼¯å’Œæ½¤è‰²çš„å®Œæ•´è«–æ–‡æ–‡æœ¬ï¼ŒåŒ…å«ï¼š

1. **æ‘˜è¦éƒ¨åˆ†**ï¼šåœ¨æ–‡ç« é–‹é ­çš„å°ˆæ¥­æ‘˜è¦ (150-250å­—)
2. **å®Œæ•´æ­£æ–‡**ï¼šç¶“éç·¨è¼¯å’Œæ½¤è‰²çš„æ‰€æœ‰ç« ç¯€
3. **æµæš¢éæ¸¡**ï¼šç« ç¯€é–“è‡ªç„¶çš„éæ¸¡
4. **çµ±ä¸€é¢¨æ ¼**ï¼šä¸€è‡´çš„å­¸è¡“å¯«ä½œé¢¨æ ¼
5. **ä¿ç•™å¼•ç”¨**ï¼šæ‰€æœ‰åŸå§‹ä¾†æºæ¨™è¨»

è«‹ç¢ºä¿æœ€çµ‚è¼¸å‡ºæ˜¯ä¸€ç¯‡å¯ä»¥ç›´æ¥ç™¼è¡¨çš„å®Œæ•´è«–æ–‡ã€‚''',
            agent=editor
        )
        
        editing_crew = Crew(
            agents=[editor],
            tasks=[review_task],
            verbose=False
        )
        
        editing_result = editing_crew.kickoff()
        
        if editing_result and editing_result.raw:
            state['final_paper_content'] = editing_result.raw
            print("ç·¨è¼¯å¯©é–±å®Œæˆ")
            state['tasks_completed'].append('editing')
        else:
            print("ç·¨è¼¯å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹åˆç¨¿")
            state['final_paper_content'] = state['draft_content']
            state['errors'].append("ç·¨è¼¯éç¨‹å¤±æ•—")
    
    except Exception as e:
        print(f"ç·¨è¼¯éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"ç·¨è¼¯éŒ¯èª¤ï¼š{str(e)}")
        state['final_paper_content'] = state['draft_content']
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('editing')
    
    return state


def citation_node(state: ResearchState) -> ResearchState:
    """
    å¼•æ–‡æ ¼å¼åŒ–ç¯€é»ï¼šç”ŸæˆAPAæ ¼å¼åƒè€ƒæ–‡ç»
    """
    print("\n=== å¼•æ–‡æ ¼å¼åŒ–éšæ®µ ===")
    
    if not state.get('final_paper_content'):
        state['errors'].append("æ²’æœ‰è«–æ–‡å…§å®¹å¯ä¾›å¼•æ–‡æ ¼å¼åŒ–")
        return state
    
    try:
        from crewai import Task
        
        # å‰µå»ºåŒ…å«è«–æ–‡å…§å®¹çš„contextä»»å‹™
        context_task = Task(
            description="Paper content for citation formatting",
            expected_output="Paper content",
            agent=citation_formatter
        )
        context_task.output = type('MockOutput', (), {
            'raw': state['final_paper_content']
        })()
        
        citation_task = create_citation_task()
        citation_task.context = [context_task]
        
        citation_crew = Crew(
            agents=[citation_formatter],
            tasks=[citation_task],
            verbose=False
        )
        
        citation_result = citation_crew.kickoff()
        
        if citation_result and citation_result.raw:
            references_content = citation_result.raw
            
            # é©—è­‰å¼•æ–‡å“è³ª
            if "æˆ‘ç¾åœ¨çŸ¥é“æœ€çµ‚ç­”æ¡ˆ" in references_content or "Final Answer" in references_content:
                references_content = "\n\n## References\n\næ³¨æ„ï¼šæ­¤è«–æ–‡åŒ…å«å¤šå€‹ç¶²è·¯ä¾†æºå¼•ç”¨ï¼Œè«‹æ‰‹å‹•é©—è­‰å’Œæ ¼å¼åŒ–åƒè€ƒæ–‡ç»ã€‚"
            elif not references_content.strip().startswith("## References"):
                references_content = "## References\n\n" + references_content.strip()
            
            state['complete_paper_content'] = state['final_paper_content'] + "\n\n" + references_content
            print("å¼•æ–‡æ ¼å¼åŒ–å®Œæˆ")
            state['tasks_completed'].append('citation')
        else:
            print("å¼•æ–‡æ ¼å¼åŒ–å¤±æ•—")
            state['complete_paper_content'] = state['final_paper_content']
            state['errors'].append("å¼•æ–‡æ ¼å¼åŒ–å¤±æ•—")
    
    except Exception as e:
        print(f"å¼•æ–‡æ ¼å¼åŒ–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å¼•æ–‡æ ¼å¼åŒ–éŒ¯èª¤ï¼š{str(e)}")
        state['complete_paper_content'] = state['final_paper_content']
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('citation')
    
    return state


def quality_check_node(state: ResearchState) -> ResearchState:
    """
    ğŸ†• æ™ºèƒ½å“è³ªå¯©æ ¸ç¯€é»ï¼šå¯¦ç¾çœŸæ­£çš„ã€Œå¯©ç¨¿æœƒã€æ¨¡å¼
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ·±åº¦å“è³ªè©•ä¼° (1-10åˆ†è©•åˆ†ç³»çµ±)
    2. å…·é«”å•é¡Œè¨ºæ–·èˆ‡æ”¹é€²å»ºè­°
    3. æ™ºèƒ½æ±ºç­–ï¼šACCEPT/REVISE/REJECT
    4. ç‰ˆæœ¬æ§åˆ¶æ•´åˆ
    5. ä¿®è¨‚è¿´åœˆç‹€æ…‹ç®¡ç†
    """
    print("\n=== æ™ºèƒ½å“è³ªå¯©æ ¸éšæ®µ ===")
    
    # ğŸ†• è¨­ç½®ä¿®è¨‚è¿´åœˆç‹€æ…‹
    state['is_in_revision_loop'] = True
    state['last_revision_timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if not state.get('draft_content'):
        state['errors'].append("æ²’æœ‰åˆç¨¿å¯ä¾›å¯©æ ¸")
        state['review_decision'] = "REJECT"
        state['review_feedback'] = "ç¼ºå°‘åˆç¨¿å…§å®¹ï¼Œç„¡æ³•é€²è¡Œå“è³ªå¯©æ ¸ã€‚"
        state['workflow_completion_status'] = "FAILED_NO_CONTENT"
        return state
    
    # ğŸ†• ç‰ˆæœ¬æ§åˆ¶ï¼šå¯©æ ¸å‰ä¿å­˜ç•¶å‰ç‰ˆæœ¬
    current_revision = state.get('revision_count', 0)
    save_version_to_history(
        state, 
        state['draft_content'], 
        f"review_{current_revision + 1}", 
        f"ç¬¬ {current_revision + 1} è¼ªå¯©æ ¸å‰çš„ç‰ˆæœ¬"
    )
    
    # æª¢æŸ¥ä¿®è¨‚æ¬¡æ•¸é™åˆ¶ - å¢å¼·çš„å¤±æ•—ä¿è­·æ©Ÿåˆ¶
    revision_count = state.get('revision_count', 0)
    max_revisions = state.get('max_revisions', 3)
    
    if revision_count >= max_revisions:
        print(f"å·²é”æœ€å¤§ä¿®è¨‚æ¬¡æ•¸é™åˆ¶ ({max_revisions})ï¼Œå•Ÿå‹•æœ€çµ‚è£æ±ºæ©Ÿåˆ¶")
        state['review_decision'] = "ACCEPT"
        state['force_accept_reason'] = f"é”åˆ°æœ€å¤§ä¿®è¨‚æ¬¡æ•¸ ({max_revisions})ï¼Œç³»çµ±å¼·åˆ¶æ¥å—ä»¥ç¢ºä¿æµç¨‹å®Œæˆ"
        state['final_decision_maker'] = "SYSTEM"
        state['workflow_completion_status'] = "COMPLETED_FORCE_ACCEPT"
        state['review_feedback'] = f"æœ€çµ‚è£æ±ºï¼šç¶“é {max_revisions} è¼ªä¿®è¨‚å¾Œï¼Œç³»çµ±æ±ºå®šæ¥å—ç•¶å‰ç‰ˆæœ¬ã€‚\n\né›–ç„¶ä»æœ‰æ”¹é€²ç©ºé–“ï¼Œä½†å·²å±•ç¾äº†AIåœ˜éšŠçš„å”ä½œæˆæœã€‚æ­¤æ±ºç­–åŸºæ–¼é˜²æ­¢ç„¡é™è¿´åœˆçš„ä¿è­·æ©Ÿåˆ¶ã€‚"
        
        # è¨˜éŒ„æœ€çµ‚è£æ±ºåˆ°ä¿®è¨‚æ­·å²
        final_record = {
            "revision_number": revision_count + 1,
            "decision": "FORCE_ACCEPT",
            "feedback": state['review_feedback'],
            "quality_score": 7,  # çµ¦äºˆåˆç†çš„åŸºæº–åˆ†æ•¸
            "revision_priority": "FINAL",
            "specific_issues": ["å·²é”æœ€å¤§ä¿®è¨‚æ¬¡æ•¸"],
            "timestamp": state['last_revision_timestamp'],
            "decision_maker": "SYSTEM"
        }
        
        if 'revision_history' not in state:
            state['revision_history'] = []
        state['revision_history'].append(final_record)
        
        return state
    
    try:
        from crewai import Task
        
        draft = state['draft_content']
        research_goal = state['research_goal']
        
        # åŒ…å«ç ”ç©¶ç›®æ¨™å’Œæ•¸æ“šåˆ†æçµæœçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        analysis_context = ""
        if state.get('data_analysis_results'):
            analysis_context = f"\n\nå¯ç”¨çš„æ•¸æ“šåˆ†æçµæœï¼š\n{state['data_analysis_results']}"
        
        # å‰µå»ºå°ˆé–€çš„å“è³ªå¯©æ ¸ä»»å‹™
        review_task = Task(
            description=f"""
            ä½ æ˜¯ä¸€ä½åœ‹éš›é ‚ç´šæœŸåˆŠçš„é¦–å¸­å¯©ç¨¿äººï¼Œå…·æœ‰æ¥µé«˜çš„å­¸è¡“æ¨™æº–ã€‚è«‹åš´æ ¼å¯©æ ¸ä»¥ä¸‹ç ”ç©¶å ±å‘Šåˆç¨¿ï¼š

            **ç ”ç©¶ç›®æ¨™ï¼š** {research_goal}
            {analysis_context}

            **å¾…å¯©æ ¸åˆç¨¿ï¼š**
            {draft}

            è«‹å¾ä»¥ä¸‹å¹¾å€‹ç¶­åº¦é€²è¡Œæ·±åº¦è©•ä¼°ï¼š

            ## 1. é‚è¼¯ä¸€è‡´æ€§åˆ†æ
            - è«–é»ä¹‹é–“æ˜¯å¦å­˜åœ¨é‚è¼¯çŸ›ç›¾ï¼Ÿ
            - æ•¸æ“šåˆ†æçµæœæ˜¯å¦èƒ½æœ‰åŠ›æ”¯æ’çµè«–ï¼Ÿ
            - ç« ç¯€é–“çš„é‚è¼¯æµç¨‹æ˜¯å¦é †æš¢ï¼Ÿ

            ## 2. è«–è­‰å……åˆ†æ€§è©•ä¼°
            - å¼•ç”¨çš„è«–é»æ˜¯å¦è¶³ä»¥æ”¯æ’æ ¸å¿ƒè§€é»ï¼Ÿ
            - æ˜¯å¦å­˜åœ¨æ˜é¡¯çš„è«–è­‰è·³èºæˆ–è­‰æ“šä¸è¶³ï¼Ÿ
            - åé§è§€é»æ˜¯å¦å¾—åˆ°å……åˆ†è¨è«–ï¼Ÿ

            ## 3. æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
            - æ˜¯å¦å……åˆ†åˆ©ç”¨äº†æ‰€æœ‰å¯ç”¨çš„æ•¸æ“šæ´å¯Ÿï¼Ÿ
            - æ•¸æ“šè§£é‡‹æ˜¯å¦æº–ç¢ºå’Œæ·±å…¥ï¼Ÿ
            - æ˜¯å¦æœ‰é‡è¦çš„æ•¸æ“šè¶¨å‹¢è¢«å¿½ç•¥ï¼Ÿ

            ## 4. å­¸è¡“è¦ç¯„æ€§
            - å¼•æ–‡æ ¼å¼æ˜¯å¦æ­£ç¢ºï¼Ÿ
            - å­¸è¡“èªè¨€æ˜¯å¦åš´è¬¹ï¼Ÿ
            - çµæ§‹æ˜¯å¦ç¬¦åˆå­¸è¡“å¯«ä½œæ¨™æº–ï¼Ÿ

            ## 5. å‰µæ–°æ€§å’Œæ·±åº¦
            - æ˜¯å¦æä¾›äº†æ–°çš„æ´å¯Ÿæˆ–è§€é»ï¼Ÿ
            - åˆ†ææ·±åº¦æ˜¯å¦è¶³å¤ ï¼Ÿ
            - æ˜¯å¦å›ç­”äº†ç ”ç©¶ç›®æ¨™ä¸­æå‡ºçš„å•é¡Œï¼Ÿ

            **é‡è¦èªªæ˜ï¼š**
            - å¦‚æœç™¼ç¾åš´é‡çš„é‚è¼¯éŒ¯èª¤ã€æ•¸æ“šèª¤ç”¨æˆ–çµè«–ä¸ç•¶ï¼Œè«‹é¸æ“‡ REJECT
            - å¦‚æœæ•´é«”æ–¹å‘æ­£ç¢ºä½†éœ€è¦æ”¹é€²ï¼Œè«‹é¸æ“‡ REVISE ä¸¦è©³ç´°èªªæ˜æ”¹é€²æ–¹å‘
            - åªæœ‰åœ¨è«–æ–‡é”åˆ°ç™¼è¡¨æ¨™æº–æ™‚æ‰é¸æ“‡ ACCEPT

            **è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼š**
            ä½ çš„æœ€çµ‚è¼¸å‡ºå¿…é ˆæ˜¯ä¸€å€‹åš´æ ¼çš„ JSON ç‰©ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
            {{
                "decision": "ACCEPT" | "REVISE" | "REJECT",
                "feedback": "è©³ç´°çš„å¯©æ ¸æ„è¦‹ã€‚å¦‚æœæ˜¯REVISEï¼Œå¿…é ˆæ˜ç¢ºæŒ‡å‡ºï¼š(1)éœ€è¦æ”¹é€²çš„å…·é«”å•é¡Œ (2)å»ºè­°çš„è§£æ±ºæ–¹æ¡ˆ (3)å¦‚æœæ¶‰åŠæ•¸æ“šå•é¡Œï¼Œéœ€è¦è¿”å›è¨ˆç®—ç§‘å­¸å®¶é‡æ–°åˆ†æçš„å…·é«”è¦æ±‚",
                "quality_score": 1-10çš„æ•´æ•¸è©•åˆ†,
                "revision_priority": "HIGH" | "MEDIUM" | "LOW",
                "specific_issues": ["å•é¡Œ1", "å•é¡Œ2", "å•é¡Œ3"]
            }}
            """,
            expected_output="åŒ…å« decisionã€feedbackã€quality_scoreã€revision_priority å’Œ specific_issues å­—æ®µçš„ JSON ç‰©ä»¶",
            agent=editor
        )
        
        # åŸ·è¡Œå¯©æ ¸
        review_crew = Crew(
            agents=[editor],
            tasks=[review_task],
            verbose=False
        )
        
        review_result = review_crew.kickoff()
        
        if review_result and review_result.raw:
            try:
                # å˜—è©¦è§£æ JSON å›æ‡‰
                review_text = review_result.raw
                
                # æå– JSON éƒ¨åˆ†
                if '{' in review_text and '}' in review_text:
                    json_start = review_text.find('{')
                    json_end = review_text.rfind('}') + 1
                    json_text = review_text[json_start:json_end]
                    review_data = json.loads(json_text)
                    
                    decision = review_data.get('decision', 'REVISE')
                    feedback = review_data.get('feedback', 'å¯©æ ¸æ„è¦‹è§£æå¤±æ•—')
                    quality_score = review_data.get('quality_score', 5)
                    revision_priority = review_data.get('revision_priority', 'MEDIUM')
                    specific_issues = review_data.get('specific_issues', [])
                    
                else:
                    # å¦‚æœæ²’æœ‰ JSONï¼Œè§£æç´”æ–‡å­—å›æ‡‰
                    decision = "REVISE"
                    feedback = review_text
                    quality_score = 5
                    revision_priority = "MEDIUM"
                    specific_issues = []
                
            except json.JSONDecodeError:
                print("å¯©æ ¸çµæœ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨ç­–ç•¥")
                decision = "REVISE"
                feedback = f"JSONè§£æå¤±æ•—ï¼ŒåŸå§‹å¯©æ ¸çµæœï¼š{review_result.raw}"
                quality_score = 5
                revision_priority = "MEDIUM"
                specific_issues = ["JSONè§£æå•é¡Œ"]
        
        else:
            print("å“è³ªå¯©æ ¸åŸ·è¡Œå¤±æ•—")
            decision = "REVISE"
            feedback = "å“è³ªå¯©æ ¸éç¨‹å¤±æ•—ï¼Œå»ºè­°æ‰‹å‹•æª¢æŸ¥åˆç¨¿å…§å®¹ã€‚"
            quality_score = 3
            revision_priority = "HIGH"
            specific_issues = ["å¯©æ ¸éç¨‹å¤±æ•—"]
        
        # ğŸ†• æ™ºèƒ½å¯©æ ¸æ­·å²è¨˜éŒ„ - åŒ…å«æ›´è±å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        revision_record = {
            "revision_number": revision_count + 1,
            "decision": decision,
            "feedback": feedback,
            "quality_score": quality_score,
            "revision_priority": revision_priority,
            "specific_issues": specific_issues,
            "timestamp": state['last_revision_timestamp'],
            "decision_maker": "AI_REVIEWER",
            "word_count": len(draft.split()),
            "has_data_analysis": bool(state.get('data_analysis_results')),
            "literature_points_count": len(state.get('literature_points', [])),
            "data_points_count": len(state.get('data_analysis_points', []))
        }
        
        if 'revision_history' not in state:
            state['revision_history'] = []
        state['revision_history'].append(revision_record)
        
        # ğŸ†• æ›´æ–°å¢å¼·çš„ç‹€æ…‹ä¿¡æ¯
        state['review_decision'] = decision
        state['review_feedback'] = feedback
        state['review_score'] = quality_score
        state['review_priority'] = revision_priority
        state['specific_issues'] = specific_issues
        
        # ğŸ†• æ™ºèƒ½æ±ºç­–åˆ†æèˆ‡ç”¨æˆ¶åé¥‹
        print(f"å¯©æ ¸æ±ºç­–ï¼š{decision}")
        print(f"å“è³ªè©•åˆ†ï¼š{quality_score}/10")
        print(f"ä¿®æ”¹å„ªå…ˆç´šï¼š{revision_priority}")
        if specific_issues:
            print(f"å…·é«”å•é¡Œï¼š{', '.join(specific_issues[:3])}...")  # åªé¡¯ç¤ºå‰3å€‹å•é¡Œ
        print(f"ğŸ’¬ å¯©æ ¸æ„è¦‹æ‘˜è¦ï¼š{feedback[:150]}...")
        
        # ğŸ†• å“è³ªè¶¨å‹¢åˆ†æ
        if len(state['revision_history']) > 1:
            previous_score = state['revision_history'][-2].get('quality_score', 0)
            score_change = quality_score - previous_score
            if score_change > 0:
                print(f"å“è³ªæå‡ï¼š+{score_change} åˆ†")
            elif score_change < 0:
                print(f"å“è³ªä¸‹é™ï¼š{score_change} åˆ†")
            else:
                print(f"å“è³ªæŒå¹³ï¼š{quality_score} åˆ†")
        
        state['tasks_completed'].append('quality_check')
        
    except Exception as e:
        print(f"å“è³ªå¯©æ ¸éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å“è³ªå¯©æ ¸éŒ¯èª¤ï¼š{str(e)}")
        state['review_decision'] = "REVISE"
        state['review_feedback'] = f"å“è³ªå¯©æ ¸éç¨‹é‡åˆ°æŠ€è¡“å•é¡Œï¼š{str(e)}ã€‚å»ºè­°æª¢æŸ¥åˆç¨¿å…§å®¹ä¸¦é‡æ–°å¯©æ ¸ã€‚"
    
    return state


def revision_node(state: ResearchState) -> ResearchState:
    """
    æ™ºèƒ½ä¿®è¨‚ç¯€é»ï¼šå¯¦ç¾åé¥‹é©…å‹•çš„å‹•æ…‹æ”¹é€²
    
    æ ¸å¿ƒå‡ç´šï¼š
    1. åŸºæ–¼å¯©æ ¸åé¥‹çš„ç²¾æº–ä¿®è¨‚
    2. ç‰ˆæœ¬æ§åˆ¶èˆ‡ä¿®è¨‚æ­·å²è¿½è¹¤
    3. æ™ºèƒ½ä¿®è¨‚ç­–ç•¥é¸æ“‡
    4. ä¿®è¨‚æˆæ•ˆè©•ä¼°
    """
    print("\n=== æ™ºèƒ½ä¿®è¨‚æ”¹é€²éšæ®µ ===")
    
    if not state.get('review_feedback'):
        state['errors'].append("æ²’æœ‰å¯©æ ¸åé¥‹å¯ä¾›ä¿®è¨‚")
        state['workflow_completion_status'] = "FAILED_NO_FEEDBACK"
        return state
    
    # å¢åŠ ä¿®è¨‚è¨ˆæ•¸
    revision_count = state.get('revision_count', 0) + 1
    state['revision_count'] = revision_count
    
    feedback = state['review_feedback']
    review_score = state.get('review_score', 5)
    review_priority = state.get('review_priority', 'MEDIUM')
    specific_issues = state.get('specific_issues', [])
    
    print(f"ğŸ“ åŸ·è¡Œç¬¬ {revision_count} æ¬¡ä¿®è¨‚")
    print(f"ğŸ“Š ç•¶å‰è©•åˆ†ï¼š{review_score}/10")
    print(f"âš¡ ä¿®è¨‚å„ªå…ˆç´šï¼š{review_priority}")
    print(f"ğŸ¯ ä¿®è¨‚ä¾æ“šï¼š{feedback[:150]}...")
    if specific_issues:
        print(f"ğŸ” é‡é»å•é¡Œï¼š{', '.join(specific_issues[:3])}...")
    
    # ğŸ†• ç‰ˆæœ¬æ§åˆ¶ï¼šä¿®è¨‚å‰ä¿å­˜
    save_version_to_history(
        state, 
        state.get('draft_content', ''), 
        f"pre_revision_{revision_count}", 
        f"ç¬¬ {revision_count} æ¬¡ä¿®è¨‚å‰çš„ç‰ˆæœ¬ (è©•åˆ†: {review_score}/10)"
    )
    
    try:
        from crewai import Task
        
        # åˆ†æåé¥‹å…§å®¹ï¼Œåˆ¤æ–·éœ€è¦å“ªç¨®é¡å‹çš„ä¿®è¨‚
        feedback_lower = feedback.lower()
        needs_data_reanalysis = any(keyword in feedback_lower for keyword in [
            'æ•¸æ“šåˆ†æ', 'çµ±è¨ˆ', 'è¨ˆç®—', 'æ•¸æ“šå•é¡Œ', 'åˆ†æçµæœ', 'æ•¸æ“šç¼ºå¤±', 'æ•¸æ“šè§£é‡‹'
        ])
        
        if needs_data_reanalysis and state.get('data_file_path'):
            print("ğŸ”¬ æª¢æ¸¬åˆ°éœ€è¦é‡æ–°é€²è¡Œæ•¸æ“šåˆ†æ")
            
            # é‡æ–°åŸ·è¡Œæ•¸æ“šåˆ†æï¼Œå¸¶ä¸Šå…·é«”çš„æ”¹é€²è¦æ±‚
            enhanced_analysis_task = create_data_analysis_task(
                state['data_file_path'], 
                state['research_goal']
            )
            
            # åœ¨ä»»å‹™æè¿°ä¸­åŠ å…¥åé¥‹è¦æ±‚
            enhanced_analysis_task.description += f"""
            
            **é‡è¦ï¼šåŸºæ–¼å¯©ç¨¿äººåé¥‹çš„æ”¹é€²è¦æ±‚ï¼š**
            {feedback}
            
            è«‹ç‰¹åˆ¥æ³¨æ„è§£æ±ºä¸Šè¿°åé¥‹ä¸­æåˆ°çš„æ•¸æ“šåˆ†æå•é¡Œï¼Œç¢ºä¿ï¼š
            1. è£œå……ä»»ä½•éºæ¼çš„æ•¸æ“šæ´å¯Ÿ
            2. ä¿®æ­£ä»»ä½•æ•¸æ“šè§£é‡‹éŒ¯èª¤
            3. æä¾›æ›´æ·±å…¥çš„çµ±è¨ˆåˆ†æ
            4. ç¢ºä¿æ•¸æ“šæ”¯æ’çµè«–çš„é‚è¼¯æ€§
            """
            
            analysis_crew = Crew(
                agents=[computational_scientist],
                tasks=[enhanced_analysis_task],
                verbose=False
            )
            
            revised_analysis = analysis_crew.kickoff()
            
            if revised_analysis and revised_analysis.raw:
                state['data_analysis_results'] = revised_analysis.raw
                
                # æ›´æ–°æ•¸æ“šåˆ†æè«–é»
                analysis_point = {
                    "sentence": revised_analysis.raw,
                    "source": f"ä¿®è¨‚å¾Œæ•¸æ“šåˆ†æ (ç¬¬{revision_count}æ¬¡)ï¼š{state['data_file_path']}"
                }
                state['data_analysis_points'] = [analysis_point]
                
                # é‡æ–°æ•´åˆè«–é»
                combined_points = []
                if state.get('literature_points'):
                    combined_points.extend(state['literature_points'])
                combined_points.extend(state['data_analysis_points'])
                state['combined_points'] = combined_points
                
                print("âœ… æ•¸æ“šåˆ†æä¿®è¨‚å®Œæˆ")
        
        # é‡æ–°å¯«ä½œï¼Œèå…¥å¯©æ ¸åé¥‹
        if state.get('outline_data') and state.get('combined_points'):
            print("âœï¸ æ ¹æ“šåé¥‹é‡æ–°å¯«ä½œ")
            
            outline_data = state['outline_data']
            all_points = state['combined_points']
            
            revised_draft = f"# {outline_data.get('title', 'ç ”ç©¶å ±å‘Š')}\n\n"
            
            for chapter in outline_data.get("chapters", []):
                chapter_title = chapter.get("chapter_title", "æœªå‘½åç« ç¯€")
                indices = chapter.get("supporting_points_indices", [])
                
                # ç²å–è©²ç« ç¯€çš„è«–é»
                chapter_points = [all_points[i] for i in indices if i < len(all_points)]
                
                print(f"ğŸ“ ä¿®è¨‚ç« ç¯€ï¼š{chapter_title}")
                
                # å‰µå»ºå¸¶æœ‰åé¥‹è¦æ±‚çš„å¯«ä½œä»»å‹™
                revision_writing_task = create_writing_task(
                    chapter_title, 
                    json.dumps(chapter_points, ensure_ascii=False, indent=2)
                )
                
                # åœ¨ä»»å‹™ä¸­åŠ å…¥å¯©æ ¸åé¥‹
                revision_writing_task.description += f"""
                
                **é‡è¦ï¼šåŸºæ–¼å¯©ç¨¿äººåé¥‹çš„ä¿®è¨‚è¦æ±‚ï¼š**
                {feedback}
                
                è«‹åœ¨å¯«ä½œæ™‚ç‰¹åˆ¥æ³¨æ„ï¼š
                1. è§£æ±ºåé¥‹ä¸­æåˆ°çš„é‚è¼¯å•é¡Œ
                2. åŠ å¼·è«–è­‰çš„å……åˆ†æ€§
                3. æ”¹é€²å­¸è¡“èªè¨€çš„åš´è¬¹æ€§
                4. ç¢ºä¿èˆ‡æ•¸æ“šåˆ†æçµæœçš„ä¸€è‡´æ€§
                5. æé«˜è«–æ–‡çš„æ•´é«”æ·±åº¦å’Œå‰µæ–°æ€§
                
                é€™æ˜¯ç¬¬ {revision_count} æ¬¡ä¿®è¨‚ï¼Œè«‹ç¢ºä¿è§£æ±ºä¹‹å‰ç‰ˆæœ¬çš„å•é¡Œã€‚
                """
                
                writing_crew = Crew(
                    agents=[academic_writer],
                    tasks=[revision_writing_task],
                    verbose=False
                )
                
                chapter_result = writing_crew.kickoff()
                
                if chapter_result and chapter_result.raw:
                    chapter_content = chapter_result.raw
                else:
                    chapter_content = f"[ç¬¬{revision_count}æ¬¡ä¿®è¨‚ï¼šç« ç¯€å…§å®¹ç”Ÿæˆå¤±æ•—]"
                
                revised_draft += f"## {chapter_title}\n\n{chapter_content}\n\n"
            
            # ğŸ†• å¢å¼·çš„ä¿®è¨‚èªªæ˜ï¼ŒåŒ…å«è©³ç´°çš„æ”¹é€²è¨˜éŒ„
            revision_summary = format_revision_history_summary(state)
            revision_note = f"""

---
## ğŸ“ ä¿®è¨‚è¨˜éŒ„ (ç¬¬ {revision_count} æ¬¡ä¿®è¨‚)

### æœ¬æ¬¡ä¿®è¨‚é‡é»
- **è©•åˆ†æå‡ç›®æ¨™**ï¼šå¾ {review_score}/10 æå‡è‡³ 8+ åˆ†
- **ä¿®è¨‚å„ªå…ˆç´š**ï¼š{review_priority}
- **é‡é»æ”¹é€²å•é¡Œ**ï¼š{', '.join(specific_issues[:3]) if specific_issues else 'æ•´é«”å“è³ªæå‡'}

### å¯©ç¨¿äººåé¥‹æ‘˜è¦
{feedback[:200]}...

### å…·é«”æ”¹é€²æªæ–½
æœ¬ç‰ˆæœ¬å·²é‡å°ä¸Šè¿°åé¥‹é€²è¡Œäº†ä»¥ä¸‹æ”¹é€²ï¼š
1. åŠ å¼·è«–è­‰é‚è¼¯æ€§å’Œé€£è²«æ€§
2. è£œå……æ•¸æ“šåˆ†æçš„æ·±åº¦å’Œæº–ç¢ºæ€§
3. æå‡å­¸è¡“èªè¨€çš„åš´è¬¹æ€§
4. ç¢ºä¿æ‰€æœ‰è«–é»éƒ½æœ‰å……åˆ†çš„è­‰æ“šæ”¯æ’

---
"""
            
            state['draft_content'] = revised_draft + revision_note
            
            # ğŸ†• ç‰ˆæœ¬æ§åˆ¶ï¼šä¿å­˜ä¿®è¨‚å¾Œç‰ˆæœ¬
            save_version_to_history(
                state, 
                state['draft_content'], 
                f"revised_{revision_count}", 
                f"ç¬¬ {revision_count} æ¬¡ä¿®è¨‚å®Œæˆç‰ˆæœ¬ (ç›®æ¨™è©•åˆ†: 8+/10)"
            )
            
            print("âœ… æ™ºèƒ½ä¿®è¨‚å®Œæˆ")
            print(f"ğŸ“ˆ é æœŸè©•åˆ†æå‡ï¼š{review_score}/10 â†’ 8+/10")
        
        # è¨˜éŒ„ä¿®è¨‚å®Œæˆ
        state['tasks_completed'].append(f'revision_{revision_count}')
        
        # ğŸ†• ä¿®è¨‚è¿´åœˆç‹€æ…‹æ›´æ–°
        state['last_revision_timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
    except Exception as e:
        print(f"âŒ ä¿®è¨‚éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"ä¿®è¨‚éŒ¯èª¤ (ç¬¬{revision_count}æ¬¡)ï¼š{str(e)}")
    
    return state


def route_after_quality_check(state: ResearchState) -> str:
    """
    ğŸ†• æ™ºèƒ½å“è³ªå¯©æ ¸è·¯ç”±ï¼šå¯¦ç¾çœŸæ­£çš„å¯©ç¨¿-ä¿®è¨‚é–‰ç’°
    
    æ ¸å¿ƒé‚è¼¯ï¼š
    1. ACCEPT â†’ editing (å¯©æ ¸é€šéï¼Œé€²å…¥æœ€çµ‚ç·¨è¼¯)
    2. REVISE + æœªé”ä¸Šé™ â†’ revision (å•Ÿå‹•ä¿®è¨‚è¿´åœˆ)
    3. REJECT æˆ– é”åˆ°ä¸Šé™ â†’ editing (æœ€çµ‚è£æ±ºï¼Œå¼·åˆ¶æ¥å—)
    4. å‹•æ…‹è¿½è¹¤ä¿®è¨‚æˆæ•ˆ
    """
    decision = state.get('review_decision', 'REVISE')
    revision_count = state.get('revision_count', 0)
    max_revisions = state.get('max_revisions', 3)
    review_score = state.get('review_score', 5)
    is_force_accept = state.get('force_accept_reason') is not None
    
    print(f"\nğŸ§­ === æ™ºèƒ½å¯©ç¨¿è·¯ç”±æ±ºç­– ===")
    print(f"ğŸ“‹ å¯©æ ¸æ±ºç­–ï¼š{decision}")
    print(f"ğŸ“Š ç•¶å‰è©•åˆ†ï¼š{review_score}/10")
    print(f"ğŸ”„ ä¿®è¨‚é€²åº¦ï¼š{revision_count}/{max_revisions}")
    if is_force_accept:
        print(f"âš–ï¸ æœ€çµ‚è£æ±ºï¼š{state.get('force_accept_reason', '')[:50]}...")
    
    # ğŸ†• æ±ºç­–å„ªå…ˆç´šï¼šå¼·åˆ¶æ¥å— > å“è³ªé€šé > ä¿®è¨‚è¿´åœˆ > ä¿è­·æ©Ÿåˆ¶
    
    # 1. æœ€çµ‚è£æ±ºï¼šå¼·åˆ¶æ¥å—
    if is_force_accept or decision == "FORCE_ACCEPT":
        print("âš–ï¸ ç³»çµ±æœ€çµ‚è£æ±º â†’ å¼·åˆ¶æ¥å—ï¼Œé€²å…¥ç·¨è¼¯éšæ®µ")
        state['is_in_revision_loop'] = False
        state['workflow_completion_status'] = "COMPLETED_FORCE_ACCEPT"
        return "editing"
    
    # 2. å“è³ªå¯©æ ¸é€šé
    if decision == "ACCEPT":
        print("âœ… å“è³ªå¯©æ ¸é€šé â†’ é€²å…¥æœ€çµ‚ç·¨è¼¯éšæ®µ")
        state['is_in_revision_loop'] = False
        state['workflow_completion_status'] = "COMPLETED_ACCEPT"
        state['quality_gates_passed'].append(f"quality_check_passed_score_{review_score}")
        return "editing"
    
    # 3. éœ€è¦ä¿®è¨‚ä¸”æœªé”ä¸Šé™
    elif decision == "REVISE" and revision_count < max_revisions:
        print(f"ğŸ”„ å•Ÿå‹•ä¿®è¨‚è¿´åœˆ â†’ ç¬¬ {revision_count + 1} æ¬¡ä¿®è¨‚")
        print(f"ğŸ¯ ä¿®è¨‚ç›®æ¨™ï¼šæå‡è©•åˆ†è‡³ 8+ åˆ†")
        state['is_in_revision_loop'] = True
        return "revision"
    
    # 4. ä¿è­·æ©Ÿåˆ¶ï¼šé”åˆ°ä¿®è¨‚ä¸Šé™æˆ–è¢«æ‹’çµ•
    else:
        if decision == "REJECT":
            print("âŒ å“è³ªå¯©æ ¸æ‹’çµ• â†’ å•Ÿå‹•ä¿è­·æ©Ÿåˆ¶ï¼Œå¼·åˆ¶æ¥å—")
            state['force_accept_reason'] = "å“è³ªå¯©æ ¸æ‹’çµ•ï¼Œä½†å•Ÿå‹•ä¿è­·æ©Ÿåˆ¶é¿å…å®Œå…¨å¤±æ•—"
        else:
            print(f"âš ï¸ é”åˆ°æœ€å¤§ä¿®è¨‚æ¬¡æ•¸ ({max_revisions}) â†’ å•Ÿå‹•ä¿è­·æ©Ÿåˆ¶ï¼Œå¼·åˆ¶æ¥å—")
            state['force_accept_reason'] = f"é”åˆ°æœ€å¤§ä¿®è¨‚æ¬¡æ•¸ {max_revisions}ï¼Œå•Ÿå‹•ä¿è­·æ©Ÿåˆ¶"
        
        state['is_in_revision_loop'] = False
        state['final_decision_maker'] = "PROTECTION_SYSTEM"
        state['workflow_completion_status'] = "COMPLETED_PROTECTION"
        return "editing"


def decision_router(state: ResearchState) -> str:
    """
    æ±ºç­–è·¯ç”±å™¨ï¼šæ ¹æ“šå°ˆæ¡ˆè¨ˆåŠƒå’Œç•¶å‰ç‹€æ…‹æ±ºå®šä¸‹ä¸€æ­¥
    """
    current_stage = state.get('current_stage', 'start')
    project_plan = state.get('project_plan', {})
    tasks_completed = state.get('tasks_completed', [])
    errors = state.get('errors', [])
    
    print(f"\nğŸ§­ æ±ºç­–è·¯ç”±å™¨ï¼šç•¶å‰éšæ®µ = {current_stage}")
    
    # å¦‚æœæœ‰åš´é‡éŒ¯èª¤ï¼ŒçµæŸæµç¨‹
    if errors and any('AuthenticationError' in error for error in errors):
        print("âŒ æª¢æ¸¬åˆ°èªè­‰éŒ¯èª¤ï¼ŒçµæŸæµç¨‹")
        return "finished"
    
    # å¦‚æœé‚„æ²’æœ‰å°ˆæ¡ˆè¨ˆåŠƒï¼Œé–‹å§‹æ–‡ç»ç ”ç©¶ä½œç‚ºå‚™ç”¨
    if 'project_planning' not in tasks_completed:
        return "literature_research"
    
    # æ ¹æ“šå°ˆæ¡ˆè¨ˆåŠƒæ±ºå®šåŸ·è¡Œé †åº
    requires_literature = project_plan.get('requires_literature', True)
    requires_data = project_plan.get('requires_data_analysis', False)
    execution_strategy = project_plan.get('execution_strategy', 'SEQUENTIAL')
    
    # æ–‡ç»ç ”ç©¶
    if requires_literature and 'literature_research' not in tasks_completed:
        return "literature_research"
    
    # æ•¸æ“šåˆ†æ
    if requires_data and 'data_analysis' not in tasks_completed:
        return "data_analysis"
    
    # æ•´åˆéšæ®µ
    if 'integration' not in tasks_completed:
        # ç¢ºä¿å‰ç½®ä»»å‹™éƒ½å·²å®Œæˆ
        literature_done = not requires_literature or 'literature_research' in tasks_completed
        data_done = not requires_data or 'data_analysis' in tasks_completed
        
        if literature_done and data_done:
            return "integration"
        else:
            # é‚„æœ‰å‰ç½®ä»»å‹™æ²’å®Œæˆï¼Œç¹¼çºŒç•¶å‰éšæ®µ
            if not literature_done:
                return "literature_research"
            elif not data_done:
                return "data_analysis"
            else:
                return "integration"
    
    # å¯«ä½œéšæ®µ
    if 'writing' not in tasks_completed:
        return "writing"
    
    # å“è³ªå¯©æ ¸éšæ®µ (æ–°å¢çš„åé¥‹é—œå¡)
    if 'quality_check' not in tasks_completed:
        return "quality_check"
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¿®è¨‚
    review_decision = state.get('review_decision')
    revision_count = state.get('revision_count', 0)
    max_revisions = state.get('max_revisions', 3)
    
    # å¦‚æœæœ‰å“è³ªå¯©æ ¸çµæœä¸”éœ€è¦ä¿®è¨‚
    if review_decision == "REVISE" and revision_count < max_revisions:
        # éœ€è¦ä¿®è¨‚ï¼Œä½†é‚„æ²’æœ‰åŸ·è¡Œç•¶å‰è¼ªæ¬¡çš„ä¿®è¨‚
        current_revision_task = f'revision_{revision_count + 1}'
        if current_revision_task not in tasks_completed:
            return "revision"
        else:
            # ä¿®è¨‚å®Œæˆï¼Œé‡æ–°é€²è¡Œå“è³ªå¯©æ ¸
            if 'quality_check' in tasks_completed:
                # ç§»é™¤ quality_check æ¨™è¨˜ï¼Œå…è¨±é‡æ–°å¯©æ ¸
                tasks_completed.remove('quality_check')
            return "quality_check"
    
    # ç·¨è¼¯éšæ®µ (å“è³ªå¯©æ ¸é€šéå¾Œ)
    if 'editing' not in tasks_completed:
        return "editing"
    
    # å¼•æ–‡æ ¼å¼åŒ–éšæ®µ
    if 'citation' not in tasks_completed:
        return "citation"
    
    # æ‰€æœ‰ä»»å‹™å®Œæˆ
    return "finished"


def create_hybrid_workflow() -> StateGraph:
    """
    å‰µå»ºLangGraphæ··åˆæ™ºèƒ½å·¥ä½œæµç¨‹ - å¸¶æœ‰å“è³ªå¯©æ ¸åé¥‹è¿´åœˆ
    """
    # åˆå§‹åŒ–ç‹€æ…‹åœ–
    workflow = StateGraph(ResearchState)
    
    # æ·»åŠ æ‰€æœ‰ç¯€é»
    workflow.add_node("project_planning", project_planning_node)
    workflow.add_node("literature_research", literature_research_node)
    workflow.add_node("data_analysis", data_analysis_node)
    workflow.add_node("integration", integration_node)
    workflow.add_node("writing", writing_node)
    workflow.add_node("quality_check", quality_check_node)      # æ–°å¢ï¼šå“è³ªå¯©æ ¸ç¯€é»
    workflow.add_node("revision", revision_node)               # æ–°å¢ï¼šä¿®è¨‚ç¯€é»
    workflow.add_node("editing", editing_node)
    workflow.add_node("citation", citation_node)
    
    # è¨­ç½®èµ·å§‹é»
    workflow.set_entry_point("project_planning")
    
    # æ·»åŠ æ¢ä»¶é‚Šï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰
    workflow.add_conditional_edges(
        "project_planning",
        decision_router,
        {
            "literature_research": "literature_research",
            "data_analysis": "data_analysis",
            "integration": "integration",
            "writing": "writing",
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing", 
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "literature_research",
        decision_router,
        {
            "data_analysis": "data_analysis",
            "integration": "integration",
            "writing": "writing",
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing",
            "citation": "citation", 
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "data_analysis",
        decision_router,
        {
            "literature_research": "literature_research",
            "integration": "integration",
            "writing": "writing",
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "integration",
        decision_router,
        {
            "writing": "writing",
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "writing",
        decision_router,
        {
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    # æ–°å¢ï¼šå“è³ªå¯©æ ¸ç¯€é»çš„æ¢ä»¶è·¯ç”±
    workflow.add_conditional_edges(
        "quality_check",
        route_after_quality_check,  # ä½¿ç”¨å°ˆé–€çš„å“è³ªå¯©æ ¸è·¯ç”±å‡½æ•¸
        {
            "revision": "revision",
            "editing": "editing",
            "finished": END
        }
    )
    
    # ğŸ†• ä¿®è¨‚ç¯€é»çš„å¼·åˆ¶è·¯ç”±ï¼šä¿®è¨‚å®Œæˆå¾Œå¿…é ˆé‡æ–°å¯©æ ¸
    def route_after_revision(state: ResearchState) -> str:
        """
        ä¿®è¨‚å¾Œçš„å¼·åˆ¶è·¯ç”±ï¼šç¢ºä¿ä¿®è¨‚å®Œæˆå¾Œå¿…é ˆå›åˆ°å“è³ªå¯©æ ¸
        é€™æ˜¯å¯¦ç¾çœŸæ­£ã€Œå¯©ç¨¿-ä¿®è¨‚ã€é–‰ç’°çš„é—œéµ
        """
        revision_count = state.get('revision_count', 0)
        max_revisions = state.get('max_revisions', 3)
        
        print(f"\nğŸ”„ ä¿®è¨‚å®Œæˆè·¯ç”±ï¼šç¬¬ {revision_count} æ¬¡ä¿®è¨‚å·²å®Œæˆ")
        print("ğŸ“‹ å¼·åˆ¶è¿”å›å“è³ªå¯©æ ¸ç¯€é»ï¼Œå¯¦ç¾é–‰ç’°åé¥‹")
        
        # æ¸…é™¤ä¸Šä¸€è¼ªçš„å¯©æ ¸æ¨™è¨˜ï¼Œå…è¨±é‡æ–°å¯©æ ¸
        tasks_completed = state.get('tasks_completed', [])
        if 'quality_check' in tasks_completed:
            tasks_completed.remove('quality_check')
            print("ğŸ”„ å·²æ¸…é™¤ä¸Šè¼ªå¯©æ ¸æ¨™è¨˜ï¼Œæº–å‚™é‡æ–°å¯©æ ¸")
        
        # ä¿®è¨‚å®Œæˆå¾Œï¼Œç„¡è«–å¦‚ä½•éƒ½è¦å›åˆ°å“è³ªå¯©æ ¸
        return "quality_check"
    
    workflow.add_conditional_edges(
        "revision",
        route_after_revision,
        {
            "quality_check": "quality_check",  # ä¿®è¨‚å¾Œå¼·åˆ¶é‡æ–°å¯©æ ¸
            "finished": END  # ç•°å¸¸æƒ…æ³çš„é€€å‡º
        }
    )
    
    workflow.add_conditional_edges(
        "editing",
        decision_router,
        {
            "quality_check": "quality_check",
            "revision": "revision",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "citation",
        decision_router,
        {
            "quality_check": "quality_check",
            "revision": "revision",
            "editing": "editing",
            "finished": END
        }
    )
    
    # ç·¨è­¯å·¥ä½œæµç¨‹
    return workflow.compile()