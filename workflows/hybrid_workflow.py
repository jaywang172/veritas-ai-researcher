#!/usr/bin/env python3
"""
Veritas Hybrid Intelligence Workflow
LangGraph-based state machine for autonomous research planning and execution.
"""

import json
from typing import Dict, List, Optional, TypedDict, Annotated
from pathlib import Path
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, AIMessage

# Import our agents and tasks
from agents import (
    project_manager, literature_scout, synthesizer, outline_planner,
    academic_writer, editor, citation_formatter, computational_scientist
)
from tasks import (
    create_research_task, create_summarize_task, create_outline_task,
    create_writing_task, create_review_task, create_citation_task,
    create_data_analysis_task
)
from crewai import Crew, Process


class ResearchState(TypedDict):
    """
    æ··åˆç ”ç©¶å·¥ä½œæµç¨‹çš„ç‹€æ…‹å®šç¾©
    åŒ…å«æ•´å€‹ç ”ç©¶éç¨‹ä¸­éœ€è¦å…±äº«çš„æ‰€æœ‰è³‡è¨Š
    """
    # è¼¸å…¥è³‡è¨Š
    research_goal: str                          # ä½¿ç”¨è€…çš„ç ”ç©¶ç›®æ¨™
    data_file_path: Optional[str]              # å¯é¸çš„è³‡æ–™æª”æ¡ˆè·¯å¾‘
    
    # å°ˆæ¡ˆè¦åŠƒ
    project_plan: Optional[Dict]               # å°ˆæ¡ˆç¶“ç†çš„ç­–ç•¥è¦åŠƒ
    
    # æ–‡ç»ç ”ç©¶çµæœ
    literature_data: Optional[str]             # åŸå§‹æ–‡ç»æœé›†è³‡æ–™
    literature_points: Optional[List[Dict]]    # æå–çš„æ–‡ç»è«–é»
    
    # æ•¸æ“šåˆ†æçµæœ
    data_analysis_results: Optional[str]       # æ•¸æ“šåˆ†ææ‘˜è¦
    data_analysis_points: Optional[List[Dict]] # æ ¼å¼åŒ–çš„åˆ†æè«–é»
    
    # æ•´åˆèˆ‡å¯«ä½œ
    combined_points: Optional[List[Dict]]      # æ•´åˆçš„è«–é»åˆ—è¡¨
    outline_data: Optional[Dict]               # è«–æ–‡å¤§ç¶±
    draft_content: Optional[str]               # åˆç¨¿å…§å®¹
    final_paper_content: Optional[str]         # ç·¨è¼¯å¾Œçš„è«–æ–‡
    complete_paper_content: Optional[str]      # åŒ…å«å¼•æ–‡çš„å®Œæ•´è«–æ–‡
    
    # å·¥ä½œæµç¨‹ç‹€æ…‹
    tasks_completed: List[str]                 # å·²å®Œæˆçš„ä»»å‹™åˆ—è¡¨
    current_stage: str                         # ç›®å‰åŸ·è¡Œéšæ®µ
    errors: List[str]                          # éŒ¯èª¤è¨˜éŒ„
    
    # LangGraph éœ€è¦çš„è¨Šæ¯ç‹€æ…‹
    messages: Annotated[List[Dict], "è¨Šæ¯æ­·å²"]


def project_planning_node(state: ResearchState) -> ResearchState:
    """
    å°ˆæ¡ˆè¦åŠƒç¯€é»ï¼šç”±å°ˆæ¡ˆç¶“ç†åˆ†æç›®æ¨™ä¸¦åˆ¶å®šåŸ·è¡Œç­–ç•¥
    """
    print("\nğŸ§  === å°ˆæ¡ˆè¦åŠƒéšæ®µ ===")
    print(f"ç ”ç©¶ç›®æ¨™ï¼š{state['research_goal']}")
    if state.get('data_file_path'):
        print(f"è³‡æ–™æª”æ¡ˆï¼š{state['data_file_path']}")
    
    # æ§‹å»ºå°ˆæ¡ˆç¶“ç†çš„åˆ†ææç¤º
    planning_prompt = f"""
    ä½œç‚ºé¦–å¸­ç ”ç©¶ç­–ç•¥å¸«ï¼Œè«‹åˆ†æä»¥ä¸‹ç ”ç©¶è«‹æ±‚ä¸¦åˆ¶å®šåŸ·è¡Œç­–ç•¥ï¼š
    
    ç ”ç©¶ç›®æ¨™ï¼š{state['research_goal']}
    è³‡æ–™æª”æ¡ˆï¼š{state.get('data_file_path', 'ç„¡')}
    
    è«‹åˆ†æä¸¦æ±ºå®šï¼š
    1. é€™å€‹ç ”ç©¶éœ€è¦ä»€éº¼é¡å‹çš„åˆ†æï¼ˆæ–‡ç»å›é¡§ã€æ•¸æ“šåˆ†æã€æˆ–å…©è€…çµåˆï¼‰
    2. æ‡‰è©²æŒ‰ä»€éº¼é †åºåŸ·è¡Œä»»å‹™
    3. å“ªäº›å°ˆå®¶ä»£ç†äººéœ€è¦åƒèˆ‡
    
    è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
    {{
        "research_type": "LITERATURE_ONLY/DATA_ONLY/HYBRID",
        "requires_literature": true/false,
        "requires_data_analysis": true/false,
        "execution_strategy": "SEQUENTIAL/PARALLEL",
        "priority_tasks": ["task1", "task2", ...],
        "reasoning": "æ±ºç­–ç†ç”±"
    }}
    """
    
    try:
        # è®“å°ˆæ¡ˆç¶“ç†åˆ†æä¸¦è¦åŠƒ
        from crewai import Task
        
        planning_task = Task(
            description=planning_prompt,
            expected_output="JSONæ ¼å¼çš„å°ˆæ¡ˆè¦åŠƒ",
            agent=project_manager
        )
        
        planning_crew = Crew(
            agents=[project_manager],
            tasks=[planning_task],
            verbose=False
        )
        
        planning_result = planning_crew.kickoff()
        
        if planning_result and planning_result.raw:
            try:
                # å˜—è©¦è§£æJSONå›æ‡‰
                plan_text = planning_result.raw
                # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœè¢«åŒ…è£åœ¨å…¶ä»–æ–‡å­—ä¸­ï¼‰
                if '{' in plan_text and '}' in plan_text:
                    json_start = plan_text.find('{')
                    json_end = plan_text.rfind('}') + 1
                    json_text = plan_text[json_start:json_end]
                    project_plan = json.loads(json_text)
                else:
                    # å¦‚æœæ²’æœ‰JSONï¼Œå‰µå»ºé»˜èªè¨ˆåŠƒ
                    project_plan = {
                        "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
                        "requires_literature": True,
                        "requires_data_analysis": bool(state.get('data_file_path')),
                        "execution_strategy": "PARALLEL",
                        "priority_tasks": ["literature_research", "data_analysis"] if state.get('data_file_path') else ["literature_research"],
                        "reasoning": "åŸºæ–¼è¼¸å…¥è‡ªå‹•åˆ¤æ–·"
                    }
                
                print(f"âœ… å°ˆæ¡ˆè¦åŠƒå®Œæˆï¼š{project_plan['research_type']}")
                print(f"ğŸ“‹ åŸ·è¡Œç­–ç•¥ï¼š{project_plan['execution_strategy']}")
                
                state['project_plan'] = project_plan
                state['current_stage'] = 'planning_completed'
                state['tasks_completed'].append('project_planning')
                
            except json.JSONDecodeError:
                print("âš ï¸ ç„¡æ³•è§£æå°ˆæ¡ˆè¦åŠƒJSONï¼Œä½¿ç”¨é»˜èªç­–ç•¥")
                state['project_plan'] = {
                    "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
                    "requires_literature": True,
                    "requires_data_analysis": bool(state.get('data_file_path')),
                    "execution_strategy": "PARALLEL",
                    "priority_tasks": ["literature_research"],
                    "reasoning": "JSONè§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨ç­–ç•¥"
                }
        else:
            print("âš ï¸ å°ˆæ¡ˆè¦åŠƒå¤±æ•—ï¼Œä½¿ç”¨é»˜èªç­–ç•¥")
            state['errors'].append("å°ˆæ¡ˆè¦åŠƒç¯€é»åŸ·è¡Œå¤±æ•—")
    
    except Exception as e:
        print(f"âŒ å°ˆæ¡ˆè¦åŠƒéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å°ˆæ¡ˆè¦åŠƒéŒ¯èª¤ï¼š{str(e)}")
        # ä½¿ç”¨å‚™ç”¨ç­–ç•¥
        state['project_plan'] = {
            "research_type": "HYBRID" if state.get('data_file_path') else "LITERATURE_ONLY",
            "requires_literature": True,
            "requires_data_analysis": bool(state.get('data_file_path')),
            "execution_strategy": "SEQUENTIAL",
            "priority_tasks": ["literature_research"],
            "reasoning": "éŒ¯èª¤æ¢å¾©ç­–ç•¥"
        }
        state['current_stage'] = 'planning_completed'
        state['tasks_completed'].append('project_planning')
    
    return state


def literature_research_node(state: ResearchState) -> ResearchState:
    """
    æ–‡ç»ç ”ç©¶ç¯€é»ï¼šæœé›†ä¸¦åˆ†æå¤–éƒ¨æ–‡ç»è³‡æ–™
    """
    print("\nğŸ“š === æ–‡ç»ç ”ç©¶éšæ®µ ===")
    
    try:
        # éšæ®µä¸€ï¼šæ–‡ç»æœé›†
        research_task = create_research_task(state['research_goal'])
        research_crew = Crew(
            agents=[literature_scout],
            tasks=[research_task],
            verbose=False
        )
        
        literature_result = research_crew.kickoff()
        if literature_result and literature_result.raw:
            state['literature_data'] = literature_result.raw
            print("âœ… æ–‡ç»æœé›†å®Œæˆ")
        else:
            state['errors'].append("æ–‡ç»æœé›†å¤±æ•—")
            return state
        
        # éšæ®µäºŒï¼šè«–é»æå–
        summarize_task = create_summarize_task()
        summarize_task.context = [research_task]
        
        synthesis_crew = Crew(
            agents=[synthesizer],
            tasks=[summarize_task],
            verbose=False
        )
        
        synthesis_result = synthesis_crew.kickoff()
        if synthesis_result and synthesis_result.raw:
            try:
                points_data = json.loads(synthesis_result.raw)
                state['literature_points'] = points_data
                print(f"âœ… æ–‡ç»è«–é»æå–å®Œæˆï¼š{len(points_data)} å€‹è«–é»")
            except json.JSONDecodeError:
                print("âš ï¸ æ–‡ç»è«–é»JSONæ ¼å¼éŒ¯èª¤")
                state['errors'].append("æ–‡ç»è«–é»è§£æå¤±æ•—")
        else:
            state['errors'].append("æ–‡ç»è«–é»æå–å¤±æ•—")
        
        state['tasks_completed'].append('literature_research')
        
    except Exception as e:
        print(f"âŒ æ–‡ç»ç ”ç©¶éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ–‡ç»ç ”ç©¶éŒ¯èª¤ï¼š{str(e)}")
    
    return state


def data_analysis_node(state: ResearchState) -> ResearchState:
    """
    æ•¸æ“šåˆ†æç¯€é»ï¼šåŸ·è¡Œæœ¬åœ°æ•¸æ“šåˆ†æ
    """
    print("\nğŸ“Š === æ•¸æ“šåˆ†æéšæ®µ ===")
    
    if not state.get('data_file_path'):
        print("âš ï¸ ç„¡æ•¸æ“šæª”æ¡ˆï¼Œè·³éæ•¸æ“šåˆ†æ")
        return state
    
    try:
        analysis_task = create_data_analysis_task(
            state['data_file_path'], 
            state['research_goal']
        )
        
        analysis_crew = Crew(
            agents=[computational_scientist],
            tasks=[analysis_task],
            verbose=False
        )
        
        analysis_result = analysis_crew.kickoff()
        
        if analysis_result and analysis_result.raw:
            state['data_analysis_results'] = analysis_result.raw
            
            # å°‡æ•¸æ“šåˆ†æçµæœæ ¼å¼åŒ–ç‚ºè«–é»
            analysis_point = {
                "sentence": analysis_result.raw,
                "source": f"æœ¬åœ°æ•¸æ“šåˆ†æï¼š{state['data_file_path']}"
            }
            state['data_analysis_points'] = [analysis_point]
            
            print("âœ… æ•¸æ“šåˆ†æå®Œæˆ")
            state['tasks_completed'].append('data_analysis')
        else:
            state['errors'].append("æ•¸æ“šåˆ†æåŸ·è¡Œå¤±æ•—")
            # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
            state['tasks_completed'].append('data_analysis')
            # æä¾›å‚™ç”¨åˆ†æçµæœ
            state['data_analysis_points'] = [{
                "sentence": "æ•¸æ“šåˆ†æåŸ·è¡Œå¤±æ•—ï¼Œç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„åˆ†æçµæœã€‚å»ºè­°æª¢æŸ¥æ•¸æ“šæ–‡ä»¶å’Œåˆ†æå·¥å…·é…ç½®ã€‚",
                "source": "æœ¬åœ°æ•¸æ“šåˆ†æ"
            }]
    
    except Exception as e:
        print(f"âŒ æ•¸æ“šåˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ•¸æ“šåˆ†æéŒ¯èª¤ï¼š{str(e)}")
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('data_analysis')
        # æä¾›å‚™ç”¨åˆ†æçµæœ
        state['data_analysis_points'] = [{
            "sentence": f"æ•¸æ“šåˆ†æéç¨‹é‡åˆ°æŠ€è¡“å•é¡Œï¼š{str(e)}ã€‚å»ºè­°æ‰‹å‹•æª¢æŸ¥æ•¸æ“šæ–‡ä»¶æ ¼å¼å’Œå…§å®¹ã€‚",
            "source": "æœ¬åœ°æ•¸æ“šåˆ†æ"
        }]
    
    return state


def integration_node(state: ResearchState) -> ResearchState:
    """
    æ•´åˆç¯€é»ï¼šçµåˆæ–‡ç»å’Œæ•¸æ“šåˆ†æçµæœï¼Œç”Ÿæˆçµ±ä¸€å¤§ç¶±
    """
    print("\nğŸ”„ === æ•´åˆèˆ‡è¦åŠƒéšæ®µ ===")
    
    try:
        # æ•´åˆæ‰€æœ‰è«–é»
        combined_points = []
        
        if state.get('literature_points'):
            combined_points.extend(state['literature_points'])
            print(f"ğŸ“š æ•´åˆæ–‡ç»è«–é»ï¼š{len(state['literature_points'])} å€‹")
        
        if state.get('data_analysis_points'):
            combined_points.extend(state['data_analysis_points'])
            print(f"ğŸ“Š æ•´åˆæ•¸æ“šåˆ†æè«–é»ï¼š{len(state['data_analysis_points'])} å€‹")
        
        state['combined_points'] = combined_points
        
        if not combined_points:
            state['errors'].append("æ²’æœ‰è«–é»å¯ä¾›æ•´åˆ")
            return state
        
        # ç”Ÿæˆçµ±ä¸€å¤§ç¶±
        outline_task = create_outline_task()
        
        # å‰µå»ºè™›æ“¬çš„contextä»»å‹™ä¾†å‚³éè«–é»è³‡æ–™
        from crewai import Task
        context_task = Task(
            description="Combined research points",
            expected_output="Research points for outline generation",
            agent=synthesizer
        )
        context_task.output = type('MockOutput', (), {
            'raw': json.dumps(combined_points, ensure_ascii=False, indent=2)
        })()
        
        outline_task.context = [context_task]
        
        outline_crew = Crew(
            agents=[outline_planner],
            tasks=[outline_task],
            verbose=False
        )
        
        outline_result = outline_crew.kickoff()
        
        if outline_result and outline_result.raw:
            try:
                outline_data = json.loads(outline_result.raw)
                state['outline_data'] = outline_data
                print(f"âœ… å¤§ç¶±ç”Ÿæˆå®Œæˆï¼š{outline_data.get('title', 'æœªçŸ¥æ¨™é¡Œ')}")
                state['tasks_completed'].append('integration')
            except json.JSONDecodeError:
                print("âš ï¸ å¤§ç¶±JSONæ ¼å¼éŒ¯èª¤")
                state['errors'].append("å¤§ç¶±è§£æå¤±æ•—")
        else:
            state['errors'].append("å¤§ç¶±ç”Ÿæˆå¤±æ•—")
    
    except Exception as e:
        print(f"âŒ æ•´åˆéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"æ•´åˆéŒ¯èª¤ï¼š{str(e)}")
    
    return state


def writing_node(state: ResearchState) -> ResearchState:
    """
    å¯«ä½œç¯€é»ï¼šæ ¹æ“šå¤§ç¶±å’Œè«–é»ç”Ÿæˆè«–æ–‡åˆç¨¿
    """
    print("\nâœï¸ === å¯«ä½œéšæ®µ ===")
    
    if not state.get('outline_data') or not state.get('combined_points'):
        state['errors'].append("ç¼ºå°‘å¤§ç¶±æˆ–è«–é»è³‡æ–™")
        return state
    
    try:
        outline_data = state['outline_data']
        all_points = state['combined_points']
        
        draft_content = f"# {outline_data.get('title', 'ç ”ç©¶å ±å‘Š')}\n\n"
        
        for chapter in outline_data.get("chapters", []):
            chapter_title = chapter.get("chapter_title", "æœªå‘½åç« ç¯€")
            indices = chapter.get("supporting_points_indices", [])
            
            # ç²å–è©²ç« ç¯€çš„è«–é»
            chapter_points = [all_points[i] for i in indices if i < len(all_points)]
            
            print(f"ğŸ“ å¯«ä½œç« ç¯€ï¼š{chapter_title}")
            
            writing_task = create_writing_task(
                chapter_title, 
                json.dumps(chapter_points, ensure_ascii=False, indent=2)
            )
            
            writing_crew = Crew(
                agents=[academic_writer],
                tasks=[writing_task],
                verbose=False
            )
            
            chapter_result = writing_crew.kickoff()
            
            if chapter_result and chapter_result.raw:
                chapter_content = chapter_result.raw
            else:
                chapter_content = "[ç« ç¯€å…§å®¹ç”Ÿæˆå¤±æ•—]"
            
            draft_content += f"## {chapter_title}\n\n{chapter_content}\n\n"
        
        state['draft_content'] = draft_content
        print("âœ… åˆç¨¿æ’°å¯«å®Œæˆ")
        state['tasks_completed'].append('writing')
    
    except Exception as e:
        print(f"âŒ å¯«ä½œéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å¯«ä½œéŒ¯èª¤ï¼š{str(e)}")
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('writing')
        state['draft_content'] = f"# ç ”ç©¶å ±å‘Š\n\nç”±æ–¼æŠ€è¡“å•é¡Œï¼Œå¯«ä½œéç¨‹æœªèƒ½å®Œæˆã€‚éŒ¯èª¤ï¼š{str(e)}\n\nè«‹æª¢æŸ¥é…ç½®ä¸¦é‡è©¦ã€‚"
    
    return state


def editing_node(state: ResearchState) -> ResearchState:
    """
    ç·¨è¼¯ç¯€é»ï¼šå°ˆæ¥­ç·¨è¼¯å¯©é–±å’Œæ½¤è‰²
    """
    print("\nğŸ¨ === ç·¨è¼¯å¯©é–±éšæ®µ ===")
    
    if not state.get('draft_content'):
        state['errors'].append("æ²’æœ‰åˆç¨¿å¯ä¾›ç·¨è¼¯")
        return state
    
    try:
        from crewai import Task
        
        # å‰µå»ºåŒ…å«åˆç¨¿çš„contextä»»å‹™
        context_task = Task(
            description="Draft content for editing",
            expected_output="Draft content",
            agent=editor
        )
        context_task.output = type('MockOutput', (), {
            'raw': state['draft_content']
        })()
        
        review_task = create_review_task()
        review_task.context = [context_task]
        
        editing_crew = Crew(
            agents=[editor],
            tasks=[review_task],
            verbose=False
        )
        
        editing_result = editing_crew.kickoff()
        
        if editing_result and editing_result.raw:
            state['final_paper_content'] = editing_result.raw
            print("âœ… ç·¨è¼¯å¯©é–±å®Œæˆ")
            state['tasks_completed'].append('editing')
        else:
            print("âš ï¸ ç·¨è¼¯å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹åˆç¨¿")
            state['final_paper_content'] = state['draft_content']
            state['errors'].append("ç·¨è¼¯éç¨‹å¤±æ•—")
    
    except Exception as e:
        print(f"âŒ ç·¨è¼¯éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"ç·¨è¼¯éŒ¯èª¤ï¼š{str(e)}")
        state['final_paper_content'] = state['draft_content']
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('editing')
    
    return state


def citation_node(state: ResearchState) -> ResearchState:
    """
    å¼•æ–‡æ ¼å¼åŒ–ç¯€é»ï¼šç”ŸæˆAPAæ ¼å¼åƒè€ƒæ–‡ç»
    """
    print("\nğŸ“š === å¼•æ–‡æ ¼å¼åŒ–éšæ®µ ===")
    
    if not state.get('final_paper_content'):
        state['errors'].append("æ²’æœ‰è«–æ–‡å…§å®¹å¯ä¾›å¼•æ–‡æ ¼å¼åŒ–")
        return state
    
    try:
        from crewai import Task
        
        # å‰µå»ºåŒ…å«è«–æ–‡å…§å®¹çš„contextä»»å‹™
        context_task = Task(
            description="Paper content for citation formatting",
            expected_output="Paper content",
            agent=citation_formatter
        )
        context_task.output = type('MockOutput', (), {
            'raw': state['final_paper_content']
        })()
        
        citation_task = create_citation_task()
        citation_task.context = [context_task]
        
        citation_crew = Crew(
            agents=[citation_formatter],
            tasks=[citation_task],
            verbose=False
        )
        
        citation_result = citation_crew.kickoff()
        
        if citation_result and citation_result.raw:
            references_content = citation_result.raw
            
            # é©—è­‰å¼•æ–‡å“è³ª
            if "æˆ‘ç¾åœ¨çŸ¥é“æœ€çµ‚ç­”æ¡ˆ" in references_content or "Final Answer" in references_content:
                references_content = "\n\n## References\n\næ³¨æ„ï¼šæ­¤è«–æ–‡åŒ…å«å¤šå€‹ç¶²è·¯ä¾†æºå¼•ç”¨ï¼Œè«‹æ‰‹å‹•é©—è­‰å’Œæ ¼å¼åŒ–åƒè€ƒæ–‡ç»ã€‚"
            elif not references_content.strip().startswith("## References"):
                references_content = "## References\n\n" + references_content.strip()
            
            state['complete_paper_content'] = state['final_paper_content'] + "\n\n" + references_content
            print("âœ… å¼•æ–‡æ ¼å¼åŒ–å®Œæˆ")
            state['tasks_completed'].append('citation')
        else:
            print("âš ï¸ å¼•æ–‡æ ¼å¼åŒ–å¤±æ•—")
            state['complete_paper_content'] = state['final_paper_content']
            state['errors'].append("å¼•æ–‡æ ¼å¼åŒ–å¤±æ•—")
    
    except Exception as e:
        print(f"âŒ å¼•æ–‡æ ¼å¼åŒ–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        state['errors'].append(f"å¼•æ–‡æ ¼å¼åŒ–éŒ¯èª¤ï¼š{str(e)}")
        state['complete_paper_content'] = state['final_paper_content']
        # å³ä½¿å¤±æ•—ä¹Ÿæ¨™è¨˜ç‚ºå·²å®Œæˆï¼Œé¿å…ç„¡é™å¾ªç’°
        state['tasks_completed'].append('citation')
    
    return state


def decision_router(state: ResearchState) -> str:
    """
    æ±ºç­–è·¯ç”±å™¨ï¼šæ ¹æ“šå°ˆæ¡ˆè¨ˆåŠƒå’Œç•¶å‰ç‹€æ…‹æ±ºå®šä¸‹ä¸€æ­¥
    """
    current_stage = state.get('current_stage', 'start')
    project_plan = state.get('project_plan', {})
    tasks_completed = state.get('tasks_completed', [])
    errors = state.get('errors', [])
    
    print(f"\nğŸ§­ æ±ºç­–è·¯ç”±å™¨ï¼šç•¶å‰éšæ®µ = {current_stage}")
    
    # å¦‚æœæœ‰åš´é‡éŒ¯èª¤ï¼ŒçµæŸæµç¨‹
    if errors and any('AuthenticationError' in error for error in errors):
        print("âŒ æª¢æ¸¬åˆ°èªè­‰éŒ¯èª¤ï¼ŒçµæŸæµç¨‹")
        return "finished"
    
    # å¦‚æœé‚„æ²’æœ‰å°ˆæ¡ˆè¨ˆåŠƒï¼Œé–‹å§‹æ–‡ç»ç ”ç©¶ä½œç‚ºå‚™ç”¨
    if 'project_planning' not in tasks_completed:
        return "literature_research"
    
    # æ ¹æ“šå°ˆæ¡ˆè¨ˆåŠƒæ±ºå®šåŸ·è¡Œé †åº
    requires_literature = project_plan.get('requires_literature', True)
    requires_data = project_plan.get('requires_data_analysis', False)
    execution_strategy = project_plan.get('execution_strategy', 'SEQUENTIAL')
    
    # æ–‡ç»ç ”ç©¶
    if requires_literature and 'literature_research' not in tasks_completed:
        return "literature_research"
    
    # æ•¸æ“šåˆ†æ
    if requires_data and 'data_analysis' not in tasks_completed:
        return "data_analysis"
    
    # æ•´åˆéšæ®µ
    if 'integration' not in tasks_completed:
        # ç¢ºä¿å‰ç½®ä»»å‹™éƒ½å·²å®Œæˆ
        literature_done = not requires_literature or 'literature_research' in tasks_completed
        data_done = not requires_data or 'data_analysis' in tasks_completed
        
        if literature_done and data_done:
            return "integration"
        else:
            # é‚„æœ‰å‰ç½®ä»»å‹™æ²’å®Œæˆï¼Œç¹¼çºŒç•¶å‰éšæ®µ
            if not literature_done:
                return "literature_research"
            elif not data_done:
                return "data_analysis"
            else:
                return "integration"
    
    # å¯«ä½œéšæ®µ
    if 'writing' not in tasks_completed:
        return "writing"
    
    # ç·¨è¼¯éšæ®µ
    if 'editing' not in tasks_completed:
        return "editing"
    
    # å¼•æ–‡æ ¼å¼åŒ–éšæ®µ
    if 'citation' not in tasks_completed:
        return "citation"
    
    # æ‰€æœ‰ä»»å‹™å®Œæˆ
    return "finished"


def create_hybrid_workflow() -> StateGraph:
    """
    å‰µå»ºLangGraphæ··åˆæ™ºèƒ½å·¥ä½œæµç¨‹
    """
    # åˆå§‹åŒ–ç‹€æ…‹åœ–
    workflow = StateGraph(ResearchState)
    
    # æ·»åŠ æ‰€æœ‰ç¯€é»
    workflow.add_node("project_planning", project_planning_node)
    workflow.add_node("literature_research", literature_research_node)
    workflow.add_node("data_analysis", data_analysis_node)
    workflow.add_node("integration", integration_node)
    workflow.add_node("writing", writing_node)
    workflow.add_node("editing", editing_node)
    workflow.add_node("citation", citation_node)
    
    # è¨­ç½®èµ·å§‹é»
    workflow.set_entry_point("project_planning")
    
    # æ·»åŠ æ¢ä»¶é‚Šï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰
    workflow.add_conditional_edges(
        "project_planning",
        decision_router,
        {
            "literature_research": "literature_research",
            "data_analysis": "data_analysis",
            "integration": "integration",
            "writing": "writing",
            "editing": "editing", 
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "literature_research",
        decision_router,
        {
            "data_analysis": "data_analysis",
            "integration": "integration",
            "writing": "writing",
            "editing": "editing",
            "citation": "citation", 
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "data_analysis",
        decision_router,
        {
            "literature_research": "literature_research",
            "integration": "integration",
            "writing": "writing",
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "integration",
        decision_router,
        {
            "writing": "writing",
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "writing",
        decision_router,
        {
            "editing": "editing",
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "editing",
        decision_router,
        {
            "citation": "citation",
            "finished": END
        }
    )
    
    workflow.add_conditional_edges(
        "citation",
        decision_router,
        {
            "finished": END
        }
    )
    
    # ç·¨è­¯å·¥ä½œæµç¨‹
    return workflow.compile()